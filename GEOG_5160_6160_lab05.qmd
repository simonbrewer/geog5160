---
title: "GEOG 5160 6160 Lab 05"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 S Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(png)
library(grid)
set.seed(42)
```

# Introduction

A frequent accusation of machine models is that they are 'black-box'; that they are so complex, it is difficult or impossible to understand how they work. In response to this, there is a growth of *interpretable* or explainable machine learning methods, designed to shed some light on the inner workings of these models. These methods provide a way to understand biases in models, but can also be useful explanatory methods to help understand your dataset. 

In this lab, we'll explore the use of the methods for both global and local interpretation using a data set of bike rentals. The goal of this exercise is to predict the number of expected rentals for any given day based on a series of factors, including season, day of the week, weather, etc. (full details in appendix 1). The data are in the file *bike.csv*, which you should download and move to a working folder for this lab. 

You will need to make sure the following packages are installed on your computer (some of these you may have already installed). Other packages for IML include **shapley** and **DALEX**

-   **iml**: interpretable machine learning
-   **vip**: variable importance plots

As a reminder, packages can be installed in RStudio by going to the 'Packages' tab and clicking on the \[Install\] button, or from the menu \[Tools\]-\> \[Install packages...\]. You can also install these from the console window by typing

```{r eval=FALSE}
install.packages("iml")
```

## Objectives

- Understand how to convert **tidymodels** output for use in interpretable machine learning
- Use methods for global and local interpretation 

We'll also revisit tuning models in this lab.

**It is highly recommended to use scripts or Quarto documents to store your R code - this will allow you to easily change and modify it and submit the exercise.**

Next load the libraries you will need for the lab. You should at this stage have most of these already installed. Add anything that is not installed using the `install.packages()` function.

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(iml)
```

## Data processing

Let's load the bike rental data first and take a look at the content:

```{r}
bike <- read.csv("./datafiles/bike.csv")
head(bike)
summary(bike)
```

```{r}
library(skimr)
skim(bike)
```

Before starting, we'll convert all categorical columns to factors and all integer columns to numeric:

```{r}
bike <- bike %>%
  mutate_if(is.character, as.factor) %>%
  mutate_if(is.integer, as.numeric) 
```

Now let's make a couple of figures. First, we'll plot the rentals over time (`days_since_2011`)

```{r}
ggplot(bike, aes(x = days_since_2011, y = count)) +
  geom_line() +
  theme_minimal()
```


There's a fairly upward trend in the data, as the rental service became more popular over time. To avoid this, we'll just work with the second year of data (2012). We'll also drop the year and `days_since_2011` columns

```{r}
bike <- bike |>
  filter(yr == 2012) |>
  dplyr::select(-days_since_2011, -yr)
```

# A base model

Next, let's develop a model for these data. We'll use a random forest here. First, let's set up and train a model without tuning. We'll go through the usual steps to set up:

- Define a recipe to one hot encode the categorical values
- Split the data into training and testing
- Use the recipe to process these datasets

```{r}
rec <- recipe(count ~ ., bike) |>
  step_dummy(all_nominal_predictors())

bike_split <- initial_split(bike, prop = 0.80)

bike_train <- training(bike_split)
bike_train = prep(rec) |> bake(bike_train)

bike_test  <- testing(bike_split)
bike_test = prep(rec) |> bake(bike_test)
```

Now, we'll build a base, untuned model, and calculate the RMSE on the test set:

```{r}
rf <- rand_forest(mode = "regression")
rf_fit <- rf |> 
  fit(count ~ ., bike_train)

pred_test <- predict(rf_fit, bike_test) |>
  bind_cols(bike_test |> dplyr::select(count))

pred_test |>
  yardstick::rmse(count, .pred)
```
Giving an RMSE of a little over 800 (your value will likely be different).

## Tuning

Now let's tune this model to get the optimal hyperparameter set. Here are the steps to set this up:

- Define the tuning specification (the model and hyperparameters)
- Define the grid (the values of each hyperparameter to test). We'll use a very similar grid to the previous example
- Define the cross-validation strategy for tuning

```{r}
## Tuning specification
tune_spec_rf <- 
  rand_forest(
    mtry = tune(),
    trees = tune(),
    min_n = tune()
  ) |> 
  set_engine("ranger") |>
  set_mode("regression")

## Tuning grid
rf_grid <- grid_regular(mtry(range = c(1, 10)),
                        trees(range = c(100, 500)),
                        min_n(range = c(2, 10)),
                        levels = 5)

## Cross-validation
bike_folds <- vfold_cv(bike_train, v = 5)
```

Now, we'll run the tuning, using **doParallel** to run this in parallel:

```{R}
doParallel::registerDoParallel()

rf_res <- 
  tune_grid(
    tune_spec_rf,
    count ~ .,
    grid = rf_grid,
    resamples = bike_folds,
    metrics = metric_set(rmse, rsq),
    control = control_grid(save_workflow = TRUE)
  )
rf_res
```

Once run, let's explore the results
```{r}
autoplot(rf_res)
```

The key hyperparameter here appears to be the number of variables used in each split, with higher values being preferred. To check this, let's get the best set of hyperparameters: 

```{r}
best_param <- select_best(rf_res, metric = "rmse") 
best_param
```

# Interpretable machine learning

We'll now explore our random forest. For the exploration, we'll first build a new model using all the rental data. This is optional, and we could equally use the best fit model from the tuning step using the `finalize_model` function. We'll use the full dataset here for a number of reasons:

- We need to fit the model again so that it calculates the importance scores (we omitted this above)
- We use the original categorical variables rather than the one-hot encoded values, as this will make visualizing the results easier (note this means that we set `mtry` to the total number of features (9) rather than the value obtained above)

```{r}
rf <- rand_forest(mode = "regression", 
                  mtry = 9, trees = 100, min_n = 2) |> 
  set_engine("ranger", importance="permutation")

rf_fit <- rf |> 
  fit(count ~ ., bike)
```

We'll also extract the trained model for use the following sections:

```{r}
rf_fit2 <- rf_fit %>%
  extract_fit_engine() 
```

## IML setup

R has a couple of packages for interpretable ML, including **iml** and **DALEX**. These work in a fairly similar way, which we'll illustrate here with the **iml** package. Rather than using the model output direct, we need to create a `Predictor` object. This holds all the information we need for subsequent analysis: the model, the features (`data`) and the target (`y`):

```{r warning=FALSE}
library(iml)
X <- bike[which(names(bike) != "count")]
predictor <- Predictor$new(rf_fit2, 
                           data = X, y = bike$count)
str(predictor)
```

## Global measures

We'll start by looking at global methods for ML interpretation. As a reminder, these are methods that evaluate the model in aggregate across the full set of observations and features. 

### Feature/variable importance

We've looked at feature importance scores in the last two labs. These are measures of how useful a variable is in predicting the target. The most common form, permutation importance, is a model-agnostic approach, that can be used with any algorithm. Here, each feature is randomly shuffled in turn, and the loss in predictive power is calculated. Bigger losses indicate that a higher level of importance. Previously, we've visualized these with the **vip** package, and we can do that again here:

```{r message=FALSE, warning=FALSE}
library(vip)
vip(rf_fit2)
```

This clearly shows temperature as being the most influential feature for bike rentals. 

Now let's remake this with the **iml** package:

```{r warning=FALSE}
imp <- FeatureImp$new(predictor, loss = "mse")
plot(imp)
```

By default, this runs 5 different permutations for each feature to get an idea of how much the importance score varies (you'll see this as line representing the variation around the mean importance on this plot). You can set this to higher number by setting `n.repetitions`.

Note that the plotting is just a **ggplot2** object, so you can add themes and text:

```{r}
plot(imp) +
  ggtitle("Feature Importance (bike rentals)") +
  theme_minimal()
```

### Partial dependence

We previously looked at partial dependency curves with the tree-based methods. These are considered to be a global interpretation method as they show the *average* response of the model over the range of a given feature. We can make these with the **iml** package using the `FeatureEffect` function. This takes as input:

- The `Predictor` object
- The feature to be plotted
- The grid size (this is the resolution of the curve, larger values will give more detail but be slower to run)
- The type of curve (`pdp` makes partial dependence plots)

We'll start by plotting the PDP for temperature as this was the most important feature:

```{r warning=FALSE}
pdp <- FeatureEffect$new(predictor, 
                         feature = "temp", 
                         grid.size = 20,
                         method = "pdp")
```

And we can plot the results

```{r}
plot(pdp)
```

The response seems pretty logical. Rentals increase as temperatures increase up to a maximum around 25 celsius. Beyond this, there is a slight decline at hotter temperatures. Let's look at the response to humidity. Note that we do not need to remake the `FeatureEffect` object, but just supply the name of another feature:

```{r}
pdp$set.feature("hum")
pdp$plot()
```

Here we can see that humidity values below about 60% have little impact on the rentals, but there is a fairly sharp drop off above this value. We can look at the combined effect of temperature and humidity with the same object, which clearly shows the sweet spot for bike rentals when temperatures are around 25 degrees and humidity around 55% (and the low rentals at low temp/high humidity)

```{r}
pdp$set.feature(c("temp", "hum"))
plot(pdp) +
  scale_fill_viridis_c(option = "magma")
```

We can also plot the response for categorical variables. For example to show the difference between seasons:

```{r}
pdp$set.feature("season")
pdp$plot()
```

A second function (`FeatureEffects`) allows you to plot the response of all features. It's worth keeping the grid size low here, at least while testing this method

```{r}
effs <- FeatureEffects$new(predictor, grid.size = 10)
plot(effs)
```

This function also allows the calculation of accumulated local effect plots. These show the *difference* in predictions as a results of changing a feature. This has the advantage of limiting bias from correlations between features, and may be a clearer way to visualize impact (i.e. positive or negative):

```{r}
ale <- FeatureEffect$new(predictor, 
                         feature = "temp", 
                         grid.size = 20,
                         method = "ale")
ale$plot()
```

### Feature interaction



interact <- Interaction$new(predictor, grid.size = 15)
plot(interact)

interact <- Interaction$new(predictor, feature = "hum", grid.size = 15)
plot(interact)

library(vivid)

bike_vivi = vivi(rf_fit_2, data = bike, response = "cnt")
viviHeatmap(bike_vivi)
viviNetwork(bike_vivi)

# Exercise

In the cancer dataset, there are two possible predictor variables that we did not use above (poverty rates `Poverty` and smoking rates `Smoking`). For the exercise, you will need run a new analysis that includes these. There are three options given below; students in GEOG 5160 will need to do one of these, students in GEOG 6160 will need to do two.

1.  Use the cancer dataset to carry out a non-spatial and spatial cross-validation, following the example above. This will be a regression task, and you should include all the possible predictors (poverty, smoking and air pollutants). You can use a random forest, or any of the other algorithms we have looked at so far. Report the RMSE and $R^2$ for both cross-validation methods, and write a short statement that explains in simple terms what these mean (1-2 sentences)
2.  Make a new geographical random forest model that includes the variables mentioned above. Your answer should include a) a variable importance plot based on the global model; b) maps of the importance scores for all variables and the local $R^2$; c) a short description (2-4 sentences) of the spatial patterns you observe
3.  Make a new model with spatial basis functions that includes the variables mentioned above. You should try at least two different basis functions setups (I'd recommend that at least one uses the irregular basis functions described in the section above). Your answer should include a) a figure showing the distribution of the basis functions you used; b) cross-validated RMSE and $R^2$ values; c) a short statement as to whether the basis functions have improved the model (1-2 sentences)

Use a Quarto document to record your answers and output. Assignments, to include both the Quarto document and (ideally) the compiled HTML file, should be submitted to Canvas by Feb 19th. Please use the following naming convention: `Lab04_lastname`.

## Appendix 1: Bike rental dataset

Bike rental dataset from https://christophm.github.io/interpretable-ml-book/bike-data.html:

- `season`: The season, either spring, summer, fall or winter.
- `year`: The year, either 2011 or 2012.
- `mnth`: The month
- `holiday`: Indicator whether the day was a holiday or not.
- `weekday`: Day of week
- `workingday`: Indicator whether the day was a working day or weekend.
- `weathersit`: The weather situation on that day. One of:
  - clear, few clouds, partly cloudy, cloudy
  - mist + clouds, mist + broken clouds, mist + few clouds, mist, light snow, light rain + thunderstorm + scattered clouds, light rain + scattered clouds
  - heavy rain + ice pallets + thunderstorm + mist, snow + mist
- `temp`: Temperature in degrees Celsius.
- `hum`: Relative humidity in percent (0 to 100).
- `windspeed`: Wind speed in km per hour.
- `count`: Count of bicycles including both casual and registered users. The count is used as the target in the regression task.
- `days_since_2011`: Number of days since the 01.01.2011 (the first day in the dataset). This feature was introduced to take account of the trend over time.

