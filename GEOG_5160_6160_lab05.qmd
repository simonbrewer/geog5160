---
title: "GEOG 5160 6160 Lab 05"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 S Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(png)
library(grid)
set.seed(42)
```

# Introduction

A frequent accusation of machine models is that they are 'black-box'; that they are so complex, it is difficult or impossible to understand how they work. In response to this, there is a growth of *interpretable* or explainable machine learning methods, designed to shed some light on the inner workings of these models. These methods provide a way to understand biases in models, but can also be useful explanatory methods to help understand your dataset. 

In this lab, we'll explore the use of the methods for both global and local interpretation using a data set of bike rentals. The goal of this exercise is to predict the number of expected rentals for any given day based on a series of factors, including season, day of the week, weather, etc. (full details in appendix 1). The data are in the file *bike.csv*, which you should download and move to a working folder for this lab. 

You will need to make sure the following packages are installed on your computer (some of these you may have already installed). Other packages for IML include **shapley** and **DALEX**

-   **iml**: interpretable machine learning
-   **vip**: variable importance plots

As a reminder, packages can be installed in RStudio by going to the 'Packages' tab and clicking on the \[Install\] button, or from the menu \[Tools\]-\> \[Install packages...\]. You can also install these from the console window by typing

```{r eval=FALSE}
install.packages("iml")
```

## Objectives

- Understand how to convert **tidymodels** output for use in interpretable machine learning
- Use methods for global and local interpretation 

We'll also revisit tuning models in this lab.

**It is highly recommended to use scripts or Quarto documents to store your R code - this will allow you to easily change and modify it and submit the exercise.**

Next load the libraries you will need for the lab. You should at this stage have most of these already installed. Add anything that is not installed using the `install.packages()` function.

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(iml)
```

## Data processing

Let's load the bike rental data first and take a look at the content:

```{r}
bike <- read.csv("./datafiles/bike.csv")
head(bike)
summary(bike)
```

```{r}
library(skimr)
skim(bike)
```

Before starting, we'll convert all categorical columns to factors and all integer columns to numeric:

```{r}
bike <- bike %>%
  mutate_if(is.character, as.factor) %>%
  mutate_if(is.integer, as.numeric) 
```

Now let's make a couple of figures. First, we'll plot the rentals over time (`days_since_2011`)

```{r}
ggplot(bike, aes(x = days_since_2011, y = count)) +
  geom_line() +
  theme_minimal()
```


There's a fairly upward trend in the data, as the rental service became more popular over time. To avoid this, we'll just work with the second year of data (2012). We'll also drop the year and `days_since_2011` columns

```{r}
bike <- bike |>
  filter(yr == 2012) |>
  dplyr::select(-days_since_2011, -yr)
```

# A base model

Next, let's develop a model for these data. We'll use a random forest here. First, let's set up and train a model without tuning. We'll go through the usual steps to set up:

- Define a recipe to one hot encode the categorical values
- Split the data into training and testing
- Use the recipe to process these datasets

```{r}
rec <- recipe(count ~ ., bike) |>
  step_dummy(all_nominal_predictors())

bike_split <- initial_split(bike, prop = 0.80)

bike_train <- training(bike_split)
bike_train = prep(rec) |> bake(bike_train)

bike_test  <- testing(bike_split)
bike_test = prep(rec) |> bake(bike_test)
```

Now, we'll build a base, untuned model, and calculate the RMSE on the test set:

```{r}
rf <- rand_forest(mode = "regression")
rf_fit <- rf |> 
  fit(count ~ ., bike_train)

pred_test <- predict(rf_fit, bike_test) |>
  bind_cols(bike_test |> dplyr::select(count))

pred_test |>
  yardstick::rmse(count, .pred)
```
Giving an RMSE of a little over 800 (your value will likely be different).

## Tuning

Now let's tune this model to get the optimal hyperparameter set. Here are the steps to set this up:

- Define the tuning specification (the model and hyperparameters)
- Define the grid (the values of each hyperparameter to test). We'll use a very similar grid to the previous example
- Define the cross-validation strategy for tuning

```{r}
## Tuning specification
tune_spec_rf <- 
  rand_forest(
    mtry = tune(),
    trees = tune(),
    min_n = tune()
  ) |> 
  set_engine("ranger") |>
  set_mode("regression")

## Tuning grid
rf_grid <- grid_regular(mtry(range = c(1, 10)),
                        trees(range = c(100, 500)),
                        min_n(range = c(2, 10)),
                        levels = 5)

## Cross-validation
bike_folds <- vfold_cv(bike_train, v = 5)
```

Now, we'll run the tuning, using **doParallel** to run this in parallel:

```{R}
doParallel::registerDoParallel()

rf_res <- 
  tune_grid(
    tune_spec_rf,
    count ~ .,
    grid = rf_grid,
    resamples = bike_folds,
    metrics = metric_set(rmse, rsq),
    control = control_grid(save_workflow = TRUE)
  )
rf_res
```

Once run, let's explore the results
```{r}
autoplot(rf_res)
```

The key hyperparameter here appears to be the number of variables used in each split, with higher values being preferred. To check this, let's get the best set of hyperparameters: 

```{r}
best_param <- select_best(rf_res, metric = "rmse") 
best_param
```

# Interpretable machine learning

We'll now explore our random forest. For the exploration, we'll first build a new model using all the data. This is optional, and we could equally use the best fit model from the tuning step using the `finalize_model` function. We'll use the full dataset here for a number of reasons:

- We're aiming to use this in an exploratory mode. If we were looking to interpret a model for prediction, we'd stick with the tuning output
- We need to cal

# Exercise

In the cancer dataset, there are two possible predictor variables that we did not use above (poverty rates `Poverty` and smoking rates `Smoking`). For the exercise, you will need run a new analysis that includes these. There are three options given below; students in GEOG 5160 will need to do one of these, students in GEOG 6160 will need to do two.

1.  Use the cancer dataset to carry out a non-spatial and spatial cross-validation, following the example above. This will be a regression task, and you should include all the possible predictors (poverty, smoking and air pollutants). You can use a random forest, or any of the other algorithms we have looked at so far. Report the RMSE and $R^2$ for both cross-validation methods, and write a short statement that explains in simple terms what these mean (1-2 sentences)
2.  Make a new geographical random forest model that includes the variables mentioned above. Your answer should include a) a variable importance plot based on the global model; b) maps of the importance scores for all variables and the local $R^2$; c) a short description (2-4 sentences) of the spatial patterns you observe
3.  Make a new model with spatial basis functions that includes the variables mentioned above. You should try at least two different basis functions setups (I'd recommend that at least one uses the irregular basis functions described in the section above). Your answer should include a) a figure showing the distribution of the basis functions you used; b) cross-validated RMSE and $R^2$ values; c) a short statement as to whether the basis functions have improved the model (1-2 sentences)

Use a Quarto document to record your answers and output. Assignments, to include both the Quarto document and (ideally) the compiled HTML file, should be submitted to Canvas by Feb 19th. Please use the following naming convention: `Lab04_lastname`.

## Appendix 1: Bike rental dataset

Bike rental dataset from https://christophm.github.io/interpretable-ml-book/bike-data.html:

- `season`: The season, either spring, summer, fall or winter.
- `year`: The year, either 2011 or 2012.
- `mnth`: The month
- `holiday`: Indicator whether the day was a holiday or not.
- `weekday`: Day of week
- `workingday`: Indicator whether the day was a working day or weekend.
- `weathersit`: The weather situation on that day. One of:
  - clear, few clouds, partly cloudy, cloudy
  - mist + clouds, mist + broken clouds, mist + few clouds, mist, light snow, light rain + thunderstorm + scattered clouds, light rain + scattered clouds
  - heavy rain + ice pallets + thunderstorm + mist, snow + mist
- `temp`: Temperature in degrees Celsius.
- `hum`: Relative humidity in percent (0 to 100).
- `windspeed`: Wind speed in km per hour.
- `count`: Count of bicycles including both casual and registered users. The count is used as the target in the regression task.
- `days_since_2011`: Number of days since the 01.01.2011 (the first day in the dataset). This feature was introduced to take account of the trend over time.

