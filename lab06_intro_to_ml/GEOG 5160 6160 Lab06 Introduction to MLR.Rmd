---
title: "GEOG 5160/6160 Lab 06 Introduction to Machine Learning in R"
author: | 
  | Simon Brewer
  | Geography Department
  | University of Utah
date: "February 18, 2020"
output:
  html_document:
    toc: true
    toc_float: true
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(png)
library(grid)
```


## Introduction

In this lab, we will introduce the basics of machine learning in R. We will repeat the example shown in class in which a linear regression model was built to predict housing prices for a set of locations in California. R has a large number of packages for individual machine learning algorithms, but also has a couple of packages that are designed to manage a machine learning workflow. These packages take care of setting up training and testing data, as well as evaluating the models. We will see in later labs that these can also be used to optimize the set up of the model.

The package we will use is called **mlr3**, which is a new version of an older package and under active development. You will need to install this, as well as a set of extensions:

- **mlr3viz**
- **mlr3learners**
- **mlr3tuning**
 
As a reminder, packages can be installed in RStudio by going to the 'Packages' tab and clicking on the [Install] button, or from the menu [Tools]-> [Install packages...]. You can also install these from the console window by typing

```{r eval=FALSE}
install.packages("mlr3")
```

More details about the **mlr3** package and the associated project can be found [here][mlr3].

You should also install the following packages to help in managing data and visualizing your results. We will not need all of these today, but will later on. 

- **dplyr**
- **rgdal**
- **raster**
- **tmap**

### Objectives

- Understand how to set up a basic linear model in R
- Use the **mlr3** package to design a ML task, a learner and a resampling strategy for validation
- Run a simple prediction with the model

**It is highly recommended to use scripts to store your R code - this will allow you to easily change and modify it and submit the exercise.**

### Data

For today's lab, we will use a data set of California house prices from the file *housing.csv*, which is available through Canvas. The data are taken from a paper by Kelley and Barry ("Sparse spatial autoregressions." Statistics & Probability Letters 33.3 (1997): 291-297), and is a classic dataset used in machine learning examples. You should also download the zipped file *ca.zip*. This contains a shapefile of California's border. 

The csv file contains the following columns most of which should be self-explanatory), with values for each California district taken from the 1990 census:

- longitude
- latitude
- housing_median_age
- total_rooms: total number of rooms in the district
- total_bedrooms: total number of bedrooms in the district
- population
- households: total number of households in the district
- median_income
- median_house_value
- ocean_proximity: a categorical value giving the position of the district relative to the ocean

The goal will be to build a model that can predict the median house value based on the other variables (or features). 

### Setting up your project

Start by creating a working directory for today's lab (e.g. called 'lab06'), and move the *housing.csv* and *ca.zip* files there. Unzip *ca.zip*. Next start RStudio (or R), and change your working directory to this directory. Check that you are in the correct place by typing the following in the console window:

```{r eval=FALSE}
list.files()
```

And make sure that you see *housing.csv* listed. Now load the file into R:

```{r}
housing <- read.csv("housing.csv")
```

## Data pre-processing

Before starting building models, we need to check and clean the data. Some things that we may want to check for are:

- missing values
- variable conversions
- outliers

Here, we'll start by loading a library to help with data processing (**dplyr**):

```{r message=FALSE}
library(dplyr)
```

Now let's check to see which of the features contain missing values. The following code uses a logical comparison (`is.na()`) to check each value in the data frame to see if it is a missing value, then the function `colSums()` counts the number of `TRUE` (i.e. missing) values per column:

```{r}
colSums(is.na(housing))
```

This tells us that the only column with missing values is `total_bedrooms`, with 207. We'll now remove these using the `filter()` function to remove the missing values. As the name might suggest, this function filters a dataset by one or more conditions (here if the `total_bedroom` value is not a missing value `na`):

```{r}
housing <- housing %>%
  filter(!is.na(total_bedrooms))
```

Next, we'll transform two variables: `total_rooms` and `total_bedrooms`. These are the total number of rooms *per district*, but as the number of households vary among districts, we can't use them directly. Instead, we'll convert these to the averager room number per house as follows:

```{r}
housing$avg_rooms = housing$total_rooms / housing$households
housing$avg_bedrooms = housing$total_bedrooms / housing$households
```

Finally, we'll make a new dataset containing only the data we want to use. For this, we use the `select()` function. Using a column name preceded by `-` will remove that column. 

```{r}
housing2 = housing %>%
  select(-longitude, -latitude, -total_rooms, -total_bedrooms, -ocean_proximity)
names(housing2)
```

## Data visualization

We'll make a few figures to visualize the data before starting. First, a histogram of `median_house_value`:

```{r}
hist(housing2$median_house_value, 
     xlab = "Median House Value", main = "CA Housing Data")
```

Note that the house value data is capped at $500,000. Next, the same for `median_income`:
```{r}
hist(housing2$median_income, 
     xlab = "Median Income", main = "CA Housing Data")
```

Now try making additional histograms for the other variables in the `housing2` data frame. The R function `names()` will give you a list of the column names if you have forgotten. 

Next, we'll make a quick map of the median house values using the **tmap** package. 

```{r}
library(rgdal)
ca.sp = readOGR("ca/ca.shp")

coordinates(housing) <- ~longitude+latitude
proj4string(housing) <- CRS("+init=EPSG:4326")

spplot(housing, "median_house_value", sp.layout = list(ca.sp))
```

And you should be able to clearly see the areas with high values around Los Angeles and the Bay Area. 

## Building a linear model

We'll start by simply building a linear regression model between the median house values and all other variables. The base R function for a linear model is `lm()`, which runs OLS regression. In general, models in R use the tilde (`~`) notation to distinguish between the outcome variable (placed on the left hand side) and the independent variables or features (on the right hand side). For a model using all the variables, we would write it as follows:

```{r}
fit1 = lm(median_house_value ~ housing_median_age + population + households + 
            median_income + avg_rooms + avg_bedrooms, data = housing2)
```

Of course, this gets pretty tedious, especially when you have a lot of independent variables. Fortunately, R has a shorthand for this, the `.` operator. The following code builds a model of `median_house_value` using *all other* variables in the `housing2` data frame. 

```{r}
fit1 = lm(median_house_value ~ ., data = housing2)
```

To see the results of the model, use the `summary()` function:

```{r}
summary(fit1)
```

This output gives the coefficients (the slope values) for each of the variables used. Most of these are straightforward to interpret (e.g. house price increases with the number of bedrooms), but others are less straightforward (e.g. house price decreases with the number of rooms). You'll get to investigate this a little further in the exercise.

## The **mlr3** package

Now we turn to the **mlr3** package to set up a machine learning framework that will be based on the same model. This framework, which we will use for most of the labs consists of the following steps:

```{r fig.width=6.5, fig.height=4., echo=FALSE}
img <- readPNG("images/ml_abstraction.png")
grid.raster(img)
```


- Define a *task*: this describes the dataset, the response variable as well as any transformations of the data that are required 
- Select a *learner*: this one of a set of machine learning algorithms that will be used to build the model
- Set up the *training* and *testing* datasets to calibrate and validate the model, respectively
- Define a *performance measure* to assess the skill of the model

Start by loading the package:

```{r}
library(mlr3)
```

### Tasks

**mlr3** defines two basic tasks: regression (for continuous variables) and classification (for categorical or binary variable). We'll use the first of these with the housing data, as the values are continuous. A regression task can be created using the `TaskRegr()` function. In this function, we specify 

- A label to describe the task
- A `backend` defining the data source (here the `housing2` data frame). Note that is quite flexible and can also include SQL databases and cloud data APIs
- A `target` defining the response variable (i.e. the thing we want to model)

```{r results='hide'}
task_housing = TaskRegr$new(id = "housing", backend = housing2, 
                            target = "median_house_value")
print(task_housing)
```

Tasks have a series of attributes that allow you to investigate the characteristics of the data:

```{r results='hide'}
## Number of observations
task_housing$nrow
## Number of features
task_housing$ncol
# See all data
task_housing$data()
# retrieve data for rows with ids 1, 51, and 101
task_housing$data(rows = c(1, 51, 101))
## Names of features and targets
task_housing$feature_names
task_housing$target_names
```

### Learners

The base **mlr3** package only comes with a few machine learning algorithms or *learners*. Mnay more are available through the **mlr3learners** package, so let's load this now.

```{r}
library(mlr3learners)
```

To see the list of available learners, type:

```{r}
mlr_learners
```

Note that this package does contain the algorithms, but acts to link a diverse range of R packages that include the machine learning methods. To get a better idea how this works, let's select a classification algorithm (a classification tree):

```{r}
learner = mlr_learners$get("classif.rpart")
print(learner)
```
The output of the `print()` function describes this particular algorithm. You should see that the functions used are from the **rpart** package, as well as information about the type of predictions that can be made and the type of features that can be included. One important part. When a learner os created, these are set to default values:

```{r}
learner$param_set
```

The linear models that we are using today do not have any parameters, but we will look at optimizing or tuning these for more complex methods in a later lab. Now create a learner for OLS regression (`regr.lm`) as follows:

```{r}
learner = mlr_learners$get("regr.lm")
print(learner)
learner$param_set
```

### Training and testing data

Next we'll create a training and testing dataset. For this first iteration of our model, we'll split the data manually into two sections, with 80% of the observations in the training set and 20% in the testing. In the following code, we 

- Set the random seed to allow for reproducibility
- Create a set of indices for the training data using the `sample()` function. The first argument `task_housing$nrow` gives the range of numbers to randomly sample (between 1 and the number of observations). The second argument `0.8 * task_housing$nrow` gives the number of random samples to take
- Create a set of indices for the testing data as the indices *not* used in the training set

```{r}
set.seed(1234)
train_set = sample(task_housing$nrow, 0.8 * task_housing$nrow)
test_set = setdiff(seq_len(task_housing$nrow), train_set)
```

To see how many observations are in each set, use the `length()` function:

```{r}
length(train_set)
length(test_set)
```

Now let's train our first model. The learner that we just created has a variable (`model`) that contains the model results. At the moment, this is empty:

```{r results='hide'}
learner$model
```

Now train the model by calling the `$train()` method of our learner. Note that we supply the `task` created earlier, and an argument giving the indices of the observations to be used in training:

```{r}
learner$train(task_housing, row_ids = train_set)
```

Now `model` contains the model output (the coefficients from the linear model)

```{r}
learner$model
```

Compare these to the results you got using the `lm()` function above. Are they the same? If not, why not?

### Prediction

Prediction in **mlr3** is fairly straightforward. We use our now-trained learner and the `$predict()` method. We specify new data by using the testing set indices created above. 

```{r}
predict_val = learner$predict(task_housing, row_ids = test_set)
print(predict_val)
```

The `print()` function displays the first few rows of these data. Note that one column holds the `truth` - the observed value, and one holds the predicted value (`response`). The **mlr3viz** package contains functions for visualizing various aspects of your model. Here, we use the `autoplot()` function to display the predicted values of the test set against the truth:

```{r}
library(mlr3viz)
autoplot(predict_val)
```

Each point represents one observation from the test set. The $x$-axis is the predicted value, and the $y$-axis the observed value. The spread of the cloud gives us some indication about the predictive skill of the learner; wider suggests a poorer performance. 

The thin black line is the 1:1 line. If the model provides an unbiased prediction, then the points should lie along this line. The blue line is a linear model fit to the points - if this matches the thin line, this is also evidence for low bias. The difference here suggests that the model may slightly over-estimate at higher house values. Note the line of observed values at about $500,000 - this is where the original data were capped, and this may affect the model's ability to predict at higher values. 

### Performance measures

THis plot allows us to visualize how well the model has predicted for the test data, but we also need to quantify this using a performance measure. This will eventually allow us to compare different learning algorithms or different setups of the same algorithm to see which is best. Not too surprisingly then, **mlr3** comes with a whole suite of different measures that we can use. To see the full list, type:

```{r}
mlr_measures
```

Note that most methods either begin with `classif.` or `regr.`, indicating what type of task they are suitable for. We create a selected measure with `msr()`, then use the `$score()` method to calculate this based on our prediction. The standard measure for regression methods is the roomt mean squared error (RMSE), so let's calculate this now:

```{r}
measure = msr("regr.rmse")
predict_val$score(measure)
```

We can also investigate the model bias:

```{r}
measure = msr("regr.bias")
predict_val$score(measure)
```

Note that we can also use these measure to assess the calibration (the goodness-of-fit). For this, we run a second prediction for the training dataset, and calculate the RMSE. 

```{r}
predict_cal = learner$predict(task_housing, row_ids = train_set)
measure = msr("regr.rmse")
predict_cal$score(measure)
```

### Resampling

So far, we have built and tested our model on a single split of the data (the hold-out method). However, if the training and testing datasets are not well set up, the estimates of modelr performance can be biased. There are several more exhaustive resampling strategies that can be used instead, and we will implment one of these now. To see the list of available strategies, type:

```{r}
mlr_resamplings
```

We will use a $k$-fold cross-validation strategy (`cv`) to test our learning algorithm. The resampler is created using the `rsmp()` function. By default, the `cv` resampler uses 10 folds, but we will adjust this to use 5, by specifying the value of `folds`:

```{r}
resampling = rsmp("cv", folds = 5)
print(resampling)
```

Note that the `Instantiated` field is set to FALSE. This simply shows that the resampler has not yet been run. 

Note that we could have created the hold-out method used above, by setting the resampler to:

```{r eval=FALSE}
rsmp("holdout", ratio = 0.8)
```

We now run the resampling strategy. To do this, we need to provide a task, so that the dataset can be divided up appropriately. This is carried out by calling the `$instantiate()` method, and the resulting indices for training and testing for the different folds are stored in the Resampling object:

```{r}
resampling$instantiate(task_housing)
resampling$iters
```

To examine any one of the training/test splits, we can obtain the list of indices or row numbers as follows:

```{r results='hide'}
resampling$train_set(1)
resampling$test_set(1)
```

Now with a task, a learner and a resampling object, we can call `resample()`, which calibrates the model using the training sets from the resampling strategy, and predicts for the test sets. The argument `store_models = TRUE` tells the function to save each individual model as it is built. 

```{r}
rr = resample(task_housing, learner, resampling, store_models = TRUE)
print(rr)
```

The output tells us that the resampler ran well, with no errors or warnings. If errors or warnings occur, you can examine them using the appropriate method:

```{r}
rr$errors
rr$warnings
```

We can now calculate the performance measures. Set the measure to the RMSE as before, then use the `$score` method (as before) to see the results for each individual fold (in the last column of output:

```{r}
measure = msr("regr.rmse")
rr$score(msr("regr.rmse"))
```

We can also get the aggregate RMSE value:

```{r}
rr$aggregate(measure)
```

As we saved all the individual models, we can explore these now. These are held in an object `$learners`:

```{r}
rr$learners
rr$learners[[1]]
```

And we can loop through all models quite simply and print out the coefficients for each one to see how much these vary across the different folds of data:

```{r}
for (i in 1:5) {
  lrn = rr$learners[[i]]
  print(coef(lrn$model))
}
```

## Appendix: The **tmap** package

The **tmap** package is an add-on to R that makes thematic maps, which are generally a little nicer looking than the default `spplot()` maps. This works by using a series of layers (not unlike making a GIS map). First, we specify a spatial object that we want to plot with `tm_shape()`, then add a geometry to this (e.g. `tm_fill()`, `tm_symbols()`, etc. Here we make a 'bubble' plot, with the size of the symbols representing the `median_house_value`:

```{r}
library(tmap)
tm_shape(ca.sp) + tm_borders() +
  tm_shape(housing) + tm_symbols("median_house_value")
```

Here, we do the same, but specify a color palette to use shading rather than size to represent value. We also specify `alpha` to make the points a little transparent.

```{r eval=FALSE}
tm_shape(ca.sp) + tm_borders() +
  tm_shape(housing) + tm_symbols("median_house_value", palette = "Reds", 
                                    alpha = 0.75, size = 0.2, border.lwd = NA)
```

Here we remake the same map, but add a title and some background colors.

```{r eval=FALSE}
tm_shape(ca.sp) + tm_borders() + tm_fill(col = "lightyellow") +
  tm_shape(housing) + tm_symbols("median_house_value", palette = "Reds", 
                                    alpha = 0.75, size = 0.2, border.lwd = NA) +
  tm_layout(bg = "grey85", legend.bg.color = "white", 
            main.title = "CA Housing Data")
```

[mlr3]: https://mlr3.mlr-org.com/reference/mlr3-package.html
