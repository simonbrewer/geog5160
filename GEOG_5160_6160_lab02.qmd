---
title: "GEOG 5160 6160 Lab 02"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 S Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(png)
library(grid)
set.seed(42)
```

# Introduction

In this lab, we will introduce the basics of machine learning in R. We will repeat the example shown in class in which a linear regression model was built to predict housing prices for a set of individual houses. Before starting the lab, you will need to set up a new folder for your working directory. Go to your `geog5160` folder now and create a new folder for today's class called `lab02`. Now use `setwd()` to make this folder your working directory.

R has a large number of packages for individual machine learning algorithms, but also has a couple of packages that are designed to manage a machine learning workflow. These packages take care of setting up training and testing data, as well as evaluating the models. We will see in later labs that these can also be used to optimize the set up of the model. The package we will use is called **tidymodels**, which contains a series of individual packages and functions focusing on different parts of the machine learning framework:

-   **parsnip**: standardized interface to algorithms
-   **yardstick**: evaluation metrics
-   **recipes**: functions for preprocessing data
-   **rsample**: functions for crosss-validation
-   **tune**: functions for tuning models
-   **workflow**: functions for setting up pipelines

As a reminder, packages can be installed in RStudio by going to the 'Packages' tab and clicking on the \[Install\] button, or from the menu \[Tools\]-\> \[Install packages...\]. You can also install these from the console window by typing

```{r eval=FALSE}
install.packages("tidymodels")
```

More details about the **tidymodels** package and the associated project can be found [here](https://www.tidymodels.org/).

## Objectives

-   Understand how to set up a basic linear model in R
-   Use the **tidymodels** package to design a ML task, a learner and a resampling strategy for validation
-   Run a simple prediction with the model

**It is highly recommended to use scripts or Quarto documents to store your R code - this will allow you to easily change and modify it and submit the exercise.**

## Data

For today's lab, we will use a data set of house prices from the file *Housing_Price_Data.csv*, which is available through Canvas. The data are taken from a Kaggle dataset [here](https://www.kaggle.com/datasets/yasserh/housing-prices-dataset).

The csv file contains the following columns most of which should be self-explanatory), with values for each California district taken from the 1990 census:

-   `price`: House price in $'s (possibly not dollars...)
-   `area`: House are in sq ft
-   `bedrooms`: number of bedrooms
-   `bathrooms`: number of bathrooms
-   `stories`: number of stories
-   `mainroad`: On main road (yes/no)
-   `guestroom`: Is there a guestroom? (yes/no)
-   `basement`: Is there a basement? (yes/no)
-   `hotwaterheating`: Is there a hot water heater? (yes/no)
-   `airconditioning`: Is there air conditioning? (yes/no)
-   `parking`: How many parking spots (0-3)
-   `prefarea`: In 'preferred' area (yes/no)
-   `furnishingstatus`: (Furnished/Semi-furnished/Unfurnished)

The goal will be to build a model that can predict the price based on the other variables (or features).

## Setting up your project

Start by creating a working directory for today's lab (e.g. called 'lab02'), and move the *Housing_Price_Data.csv* and *ca.zip* files there. Unzip *ca.zip*. Next start RStudio (or R), and change your working directory to this directory. Check that you are in the correct place by typing the following in the console window:

```{r eval=FALSE}
list.files("./datafiles")
```

And make sure that you see *housing.csv* listed. Now load the file into R:

```{r}
housing <- read.csv("./datafiles/housing.csv")
```

# Data pre-processing

Before starting building models, we need to check and clean the data. Some things that we may want to check for are:

-   missing values
-   variable conversions
-   outliers

Here, we'll start by loading a library to help with data processing (**dplyr**):

```{r message=FALSE}
library(dplyr)
```

Now let's check to see which of the features contain missing values. The following code uses a logical comparison (`is.na()`) to check each value in the data frame to see if it is a missing value, then the function `colSums()` counts the number of `TRUE` (i.e. missing) values per column:

```{r}
colSums(is.na(housing))
```

This tells us that the only column with missing values is `total_bedrooms`, with 207. We'll now remove these using the `filter()` function to remove the missing values. As the name might suggest, this function filters a dataset by one or more conditions (here if the `total_bedroom` value is not a missing value `na`). We're using **dplyr**'s `filter` function to select observations. The `%>%` operator acts as a pipe, and forwards data from the `housing` dataframe to the `filter` function:

```{r}
housing <- housing %>%
  filter(!is.na(total_bedrooms))
```

## Data visualization

We'll make a few figures to visualize the data before starting. First, a histogram of `median_house_value`:

```{r}
hist(housing$median_house_value, 
     xlab = "Median House Value", main = "CA Housing Data")
```

Note that the house value data is capped at \$500,000. Next, the same for `median_income`:

```{r}
hist(housing$median_income, 
     xlab = "Median Income", main = "CA Housing Data")
```

Now try making additional histograms for the other variables in the `housing2` data frame. The R function `names()` will give you a list of the column names if you have forgotten.

A few things to note here.

-   The `median_house_value` and `housing_median_age` are both clearly capped at an upper limit (about 50,000 and 50 respectively). We may want to remove observations at these values (or ideally find the correct values)
-   The data are on a variety of different scales
-   Several of the variables are right-skewed, and may need transforming to improve our models

The variables `total_rooms` and `total_bedrooms` represent the total number of rooms *per district*, but as the number of households vary among districts, we can't use them directly. Instead, we'll use these to create the average number of rooms per house, and the ratio of bedrooms to rooms.

```{r}
housing$avg_rooms = housing$total_rooms / housing$households
housing$bedroom_ratio = housing$total_bedrooms / housing$total_rooms
```

Next, we'll visualize some of the data, starting with a quick map of the median house values. For this we first convert to an `sf` or [simple features](https://r-spatial.github.io/sf/articles/sf1.html) object. (The `crs` parameter defines the coordinate reference system or projection using an EPSG numeric code (4326 = WGS 84). For more detail on these codes, go [here](https://spatialreference.org/ref/epsg/).)

```{r}
library(sf)
ca_sf = st_read("./datafiles/ca/ca.shp")
st_crs(ca_sf) <- 4326

housing <- st_as_sf(housing, 
                    coords = c("longitude", "latitude"),
                    crs = 4326)
```

You can map these values using R's `plot()` function as follows. First we map the geometry of the California border, then add symbols for the `median_house_value` variable.

```{r}
plot(st_geometry(ca_sf))
plot(housing["median_house_value"], add = TRUE, pch = 16, alpha = 0.25)
```

And you should be able to clearly see the areas with high values around Los Angeles and the Bay Area.

### The **tmap** package

The **tmap** package is an add-on to R that makes thematic maps, which are generally a little nicer looking than the default `spplot()` maps. This works by using a series of layers (not unlike making a GIS map). First, we specify a spatial object that we want to plot with `tm_shape()`, then add a geometry to this (e.g. `tm_fill()`, `tm_symbols()`, etc. Here we make a 'bubble' plot, with the size of the symbols representing the `median_house_value`:

```{r}
library(tmap)
tm_shape(ca_sf) + tm_borders() +
  tm_shape(housing) + tm_symbols("median_house_value")
```

Here, we do the same, but specify a color palette to use shading rather than size to represent value. We also specify `alpha` to make the points a little transparent.

```{r eval=FALSE}
tm_shape(ca_sf) + tm_borders() +
  tm_shape(housing) + tm_symbols("median_house_value", palette = "Reds", 
                                    alpha = 0.75, size = 0.2, border.lwd = NA)
```

Here we remake the same map, but add a title and some background colors.

```{r eval=TRUE}
tm_shape(ca_sf) + tm_borders() + tm_fill(col = "lightyellow") +
  tm_shape(housing) + tm_symbols("median_house_value", palette = "Reds", 
                                    alpha = 0.75, size = 0.2, border.lwd = NA) +
  tm_layout(bg = "grey85", legend.bg.color = "white", 
            main.title = "CA Housing Data")
```

For our first model, we're only going to use a subset of the variables representing building characteristics (average number of rooms, bedroom ratio and age). There are several steps here:

-   The `geometry` column contains the coordinates for each district, and this can be removed by setting it to `NULL`
-   We use `filter` to remove all districts where the value is above \$500K. As the data is capped here, using these districts would bias our model at high values
-   We use the `select()` function to choose the columns that we want to include

```{r}
names(housing)
housing2 = housing %>%
  st_set_geometry(NULL) %>%
  filter(median_house_value <= 500000) %>%
  select(median_house_value, avg_rooms, bedroom_ratio, housing_median_age)
names(housing2)
```

# Building a linear model

We'll start by simply building a linear regression model between the median house values and all other variables. The base R function for a linear model is `lm()`, which runs OLS regression. In general, models in R use the tilde (`~`) notation to distinguish between the outcome variable (placed on the left hand side) and the independent variables or features (on the right hand side). For a model using all the variables, we would write it as follows:

```{r}
fit1 = lm(median_house_value ~ housing_median_age + avg_rooms + bedroom_ratio,
          data = housing2)
```

Of course, this gets pretty tedious, especially when you have a lot of independent variables. Fortunately, R has a shorthand for this, the `.` operator. The following code builds a model of `median_house_value` using *all other* variables in the `housing2` data frame (this is why we removed the extraneous variables in a previous step).

```{r}
fit1 = lm(median_house_value ~ ., data = housing2)
```

To see the results of the model, use the `summary()` function:

```{r}
summary(fit1)
```

This output gives the coefficients (the slope values) for each of the variables used. Most of these are straightforward to interpret (e.g. house price increases with the age of the property), but others are less straightforward (e.g. house price decreases with the ratio of bedrooms to total rooms). In addition, the `R-squared` value here is small ($\approx0.06$), which suggests this is not a great model. You'll get to investigate this a little further in the exercise.

# The **mlr3** package

Now we turn to the **mlr3** package to set up a machine learning framework that will be based on the same model. This framework, which we will use for most of the labs consists of the following steps:

```{r fig.width=6.5, fig.height=4., echo=FALSE}
img <- readPNG("./images/ml_abstraction.png")
grid.raster(img)
```

-   Define a *task*: this describes the dataset, the response variable as well as any transformations of the data that are required
-   Select a *learner*: this one of a set of machine learning algorithms that will be used to build the model
-   Set up the *training* and *testing* datasets to calibrate and validate the model, respectively
-   Define a *performance measure* to assess the skill of the model

Start by loading the package:

```{r}
library(mlr3)
```

## Tasks

**mlr3** defines two basic tasks: regression (for continuous variables) and classification (for categorical or binary variable). We'll use the first of these with the housing data, as the values are continuous. A regression task can be created using the `TaskRegr()` function. In this function, we specify

-   A label to describe the task
-   A `backend` defining the data source (here the `housing2` data frame). Note that is quite flexible and can also include SQL databases and cloud data APIs
-   A `target` defining the response variable (i.e. the thing we want to model)

```{r results='hide'}
task_housing = TaskRegr$new(id = "housing", backend = housing2, 
                            target = "median_house_value")
print(task_housing)
```

Tasks have a series of attributes that allow you to investigate the characteristics of the data:

```{r results='hide'}
## Number of observations
task_housing$nrow
## Number of features
task_housing$ncol
# See all data
task_housing$data()
# retrieve data for rows with ids 1, 51, and 101
task_housing$data(rows = c(1, 51, 101))
## Names of features 
task_housing$feature_names
## Name of target variable
task_housing$target_names
```

## Learners

The base **mlr3** package only comes with a few machine learning algorithms or *learners*. Many more are available through the **mlr3learners** package, so let's load this now.

```{r}
library(mlr3learners)
```

To see the list of available learners, type:

```{r}
mlr_learners
```

Note that this package does not contain the algorithms, but acts to link a diverse range of R packages that include the machine learning methods. To get a better idea of how this works, let's select a classification algorithm (a classification tree):

```{r}
learner = mlr_learners$get("classif.rpart")
print(learner)
```

The output of the `print()` function describes this particular algorithm. You should see that the functions used are from the **rpart** package, as well as information about the type of predictions that can be made and the type of features that can be included. This also lists the current set of parameters (or hyper-parameters) for that particular algorithm. When a learner is created, these are set to default values, and you can see the full list of these by typing:

```{r}
learner$param_set
```

The linear models that we are using today do not have any parameters that we want to adjust, but we will look at optimizing or tuning these for more complex methods in a later lab. Now create a learner for OLS regression (`regr.lm`) as follows:

```{r}
learner = mlr_learners$get("regr.lm")
print(learner)
learner$param_set
```

## Training and testing data

Next we'll create a training and testing dataset. For this first iteration of our model, we'll split the data manually into two sections, with 80% of the observations in the training set and 20% in the testing. In the following code, we:

-   Set the random seed to allow for reproducibility (this is optional)
-   Create a set of indices for the training data using the `sample()` function. The first argument `task_housing$nrow` gives the range of numbers to randomly sample (between 1 and the number of observations). The second argument `0.8 * task_housing$nrow` gives the number of random samples to take
-   Create a set of indices for the testing data as the indices *not* used in the training set

The `set.seed()` function just re-initializes R's random number generator to the same value. This should ensure that you always get the same random split. You can skip this line if you'd like to see how much the results might vary if you have a different split into training and testing datasets.

```{r}
set.seed(1234)
train_set = sample(task_housing$nrow, 0.8 * task_housing$nrow)
test_set = setdiff(seq_len(task_housing$nrow), train_set)
```

To see how many observations are in each set, use the `length()` function:

```{r}
length(train_set)
length(test_set)
```

Now let's train our first model. The learner that we just created has a variable (`model`) that contains the model results. At the moment, this is empty:

```{r results='hide'}
learner$model
```

Now train the model by calling the `$train()` method of our learner. Note that we supply the `task` created earlier, and an argument giving the indices of the observations to be used in training:

```{r}
learner$train(task_housing, row_ids = train_set)
```

Now `model` contains the model output (the coefficients from the linear model).

```{r}
learner$model
```

Compare these to the results you got using the `lm()` function above. Are they the same? If not, why not?

## Prediction

Prediction in **mlr3** is fairly straightforward. We use our now-trained learner and the `$predict()` method. We specify new data by using the testing set indices created above.

```{r}
predict_val = learner$predict(task_housing, row_ids = test_set)
print(predict_val)
```

The `print()` function displays the first few rows of these data. Note that one column holds the `truth` - the observed value, and one holds the predicted value (`response`). The **mlr3viz** package contains functions for visualizing various aspects of your model. Here, we use the `autoplot()` function to display the predicted values of the test set against the truth:

```{r}
library(mlr3viz)
autoplot(predict_val)
```

Each point represents one observation from the test set. The $x$-axis is the predicted value, and the $y$-axis the observed value. The spread of the cloud gives us some indication about the predictive skill of the learner; wider suggests a poorer performance.

The thin black line is the 1:1 line. If the model provides an unbiased prediction, then the points should lie along this line. The blue line is a linear model fit to the points - if this matches the thin line, this is also evidence for low bias. The difference here suggests that the model may slightly over-estimate at higher house values. One thing to note here is that there are several districts where the house prices are predicted to be negative. This is obviously incorrect (unless they are paying people to take a house). Transforming the outcome variable (e.g. log transformation) would help avoid this problem.

## Performance measures

This plot allows us to visualize how well the model has predicted for the test data, but we also need to quantify this using a performance measure. This will eventually allow us to compare different learning algorithms or different setups of the same algorithm to see which is best. Not too surprisingly then, **mlr3** comes with a whole suite of different measures that we can use. To see the full list, type:

```{r}
mlr_measures
```

Note that most methods either begin with `classif.` or `regr.`, indicating what type of task they are suitable for. We create a selected measure with `msr()`, then use the `$score()` method to calculate this based on our prediction. One standard measure for regression methods is the root mean squared error (RMSE), so let's calculate this now:

```{r}
measure = msr("regr.rmse")
predict_val$score(measure)
```

Another common measure is the mean absolute error (MAE):

```{r}
measure = msr("regr.mae")
predict_val$score(measure)
```

We can also investigate the model bias:

```{r}
measure = msr("regr.bias")
predict_val$score(measure)
```

Note that we can also use these measure to assess the calibration (the goodness-of-fit). For this, we run a second prediction for the training dataset, and calculate the RMSE.

```{r}
predict_cal = learner$predict(task_housing, row_ids = train_set)
measure = msr("regr.rmse")
predict_cal$score(measure)
```

The RMSE is a good measure of the *average* error. It's worth noting here that this suggests our error is pretty large, over \$90,000 dollars relative the actual price.

## Resampling

So far, we have built and tested our model on a single split of the data (the hold-out method). However, if the training and testing datasets are not well set up, the estimates of model performance can be biased. There are several more exhaustive resampling strategies that can be used instead, and we will implement one of these now. To see the list of available strategies, type:

```{r}
mlr_resamplings
```

We will use a $k$-fold cross-validation strategy (`cv`) to test our learning algorithm. The resampler is created using the `rsmp()` function. By default, the `cv` resampler uses 10 folds, but we will adjust this to use 5, by specifying the value of `folds`:

```{r}
resampling = rsmp("cv", folds = 5)
print(resampling)
```

Note that the `Instantiated` field is set to FALSE. This simply shows that the resampler has not yet been run.

Note that we could have created the hold-out method used above, by setting the resampler to:

```{r eval=FALSE}
rsmp("holdout", ratio = 0.8)
```

We now run the resampling strategy. To do this, we need to provide a task, so that the dataset can be divided up appropriately. This is carried out by calling the `$instantiate()` method, and the resulting indices for training and testing for the different folds are stored in the `resampling` object:

```{r}
resampling$instantiate(task_housing)
resampling$iters
```

To examine any one of the training/test splits, we can obtain the list of indices or row numbers as follows:

```{r results='hide'}
resampling$train_set(1)
resampling$test_set(1)
```

Now with a task, a learner and a resampling object, we can call `resample()`, which calibrates the model using the training sets from the resampling strategy, and predicts for the test sets. The argument `store_models = TRUE` tells the function to save each individual model as it is built.

```{r}
rr = resample(task_housing, learner, resampling, store_models = TRUE)
print(rr)
```

The output tells us that the resampler ran well, with no errors or warnings. If errors or warnings occur, you can examine them using the appropriate method:

```{r results='hide'}
rr$errors
rr$warnings
```

We can now calculate the performance measures. Set the measure to the RMSE as before, then use the `$score` method (as before) to see the results for each individual fold (in the last column of output:

```{r}
measure = msr("regr.rmse")
rr$score(msr("regr.rmse"))
```

We can also get the aggregate RMSE value:

```{r}
rr$aggregate(measure)
```

As we saved all the individual models, we can explore these now. These are held in an object `$learners`:

```{r}
rr$learners
rr$learners[[1]]
```

And we can loop through all models quite simply and print out the coefficients for each one to see how much these vary across the different folds of data:

```{r}
for (i in 1:5) {
  lrn = rr$learners[[i]]
  print(coef(lrn$model))
}
```

# Changing model

We're going to be looking a wide range of different algorithms for machine learning over the next few weeks. This section is just designed to show how easy it is to switch out the method you are using to try a different approach. Here, we'll try using a penalized linear model, the Lasso. To test this, we simply need to define a new learner using the appropriate function (here: `regr.glmnet`). One small addition here is that we set a couple of model parameters (we'll look more in detail at model parameters in the next lab):

-   `alpha`: this is the mixing ratio. `alpha = 1` provides the Lasso algorithm (`= 0` results in ridge regression)
-   `lambda`: this the penalty weight

```{r results='hide'}
mlr_learners
learner2 = mlr_learners$get("regr.glmnet")
print(learner)
learner2$param_set
learner2$param_set$values = list(alpha = 1, lambda = 1e-3)
learner$param_set$values
```

```{r echo=FALSE}
learner$param_set$values
```

Now we've set this up, let's train it (using the previous training set)

```{r}
learner2$train(task_housing, row_ids = train_set)
```

To cross-validate, we can simply reuse the resampler we defined earlier:

```{r}
rr = resample(task_housing, learner2, resampling, store_models = TRUE)
print(rr)
rr$aggregate(measure)
```

In this case, there is little improvement with this new algorithm, but hopefully this demonstrates how easy it is to test a set of ML approaches through the API.

# Exercise

Use a word document to record your answers and output. Assignments, to include both the word document and R script file, should be submitted to Canvas. Ensure your assignment has been saved using the following naming convention: Lab06_lastname_script and Lab06_lastname_report.

As we noted during the lab, our original model some odd effects, and had pretty poor predictive power. We'll try to improve on this by adding in extra features. The following code recreates the `housing2` data frame with a larger set of data. Note that previously we used the `select` function to choose which variables to include, here we use it with `-` in from of the variables we wish to *exclude*:

```{r results='hide'}
names(housing)
housing2 = housing %>%
  st_set_geometry(NULL) %>%
  filter(median_house_value <= 500000) %>%
  select(-total_rooms, -total_bedrooms, -ocean_proximity)
names(housing2)
```

For the exercise, you need to

1.  Remake the basic linear model with this new dataset. Provide the output from the `summary()` function (either as a screenshot or copy-paste) \[1\]
2.  Make a new task for machine learning this new dataset \[1\]
3.  Repeat the resampling strategy with the new task, but with a 10-fold cross validation (i.e. `folds = 10`). Provide the set of 10 RMSE values and the aggregate RMSE \[2\]
4.  Comment on whether you think this new model is better or worse at predictions than the mode you built in the lab \[1\]
