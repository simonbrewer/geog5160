{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beijing Pollution\n",
    "\n",
    "Third script uses 3 previous lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('./data/pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12977867, 0.35294122, 0.24590163, 0.5272732 , 0.6666667 ,\n",
       "        0.00229001, 0.        , 0.        ],\n",
       "       [0.14889336, 0.36764708, 0.24590163, 0.5272732 , 0.6666667 ,\n",
       "        0.00381099, 0.        , 0.        ],\n",
       "       [0.15995975, 0.4264706 , 0.22950819, 0.545454  , 0.6666667 ,\n",
       "        0.00533197, 0.        , 0.        ],\n",
       "       [0.18209255, 0.48529413, 0.22950819, 0.5636368 , 0.6666667 ,\n",
       "        0.00839101, 0.03703704, 0.        ],\n",
       "       [0.13883299, 0.48529413, 0.22950819, 0.5636368 , 0.6666667 ,\n",
       "        0.00991199, 0.07407407, 0.        ],\n",
       "       [0.10965794, 0.48529413, 0.21311474, 0.5636368 , 0.6666667 ,\n",
       "        0.01143297, 0.11111111, 0.        ],\n",
       "       [0.1056338 , 0.48529413, 0.21311474, 0.5818176 , 0.6666667 ,\n",
       "        0.01449201, 0.14814815, 0.        ],\n",
       "       [0.12474848, 0.48529413, 0.22950819, 0.6000004 , 0.6666667 ,\n",
       "        0.01755106, 0.        , 0.        ],\n",
       "       [0.12072434, 0.47058827, 0.21311474, 0.6000004 , 0.6666667 ,\n",
       "        0.0206101 , 0.        , 0.        ],\n",
       "       [0.13279678, 0.48529413, 0.22950819, 0.61818314, 0.6666667 ,\n",
       "        0.02366915, 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "scaled[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43799, 16)\n"
     ]
    }
   ],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 1\n",
    "n_features = 8\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43795</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.763638</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43796</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.405588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.405588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43798</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.420866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43799</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.420866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.426216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43799 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1       0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "2       0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "3       0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "4       0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "5       0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "43795   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730   \n",
       "43796   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659   \n",
       "43797   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588   \n",
       "43798   0.010060   0.264706   0.262295   0.781818   0.333333   0.413996   \n",
       "43799   0.008048   0.264706   0.245902   0.781818   0.333333   0.420866   \n",
       "\n",
       "       var7(t-1)  var8(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
       "1       0.000000        0.0  0.148893  0.367647  0.245902  0.527273  0.666667   \n",
       "2       0.000000        0.0  0.159960  0.426471  0.229508  0.545454  0.666667   \n",
       "3       0.000000        0.0  0.182093  0.485294  0.229508  0.563637  0.666667   \n",
       "4       0.037037        0.0  0.138833  0.485294  0.229508  0.563637  0.666667   \n",
       "5       0.074074        0.0  0.109658  0.485294  0.213115  0.563637  0.666667   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "43795   0.000000        0.0  0.008048  0.250000  0.278689  0.781818  0.333333   \n",
       "43796   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333   \n",
       "43797   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333   \n",
       "43798   0.000000        0.0  0.008048  0.264706  0.245902  0.781818  0.333333   \n",
       "43799   0.000000        0.0  0.012072  0.279412  0.262295  0.781818  0.333333   \n",
       "\n",
       "        var6(t)   var7(t)  var8(t)  \n",
       "1      0.003811  0.000000      0.0  \n",
       "2      0.005332  0.000000      0.0  \n",
       "3      0.008391  0.037037      0.0  \n",
       "4      0.009912  0.074074      0.0  \n",
       "5      0.011433  0.111111      0.0  \n",
       "...         ...       ...      ...  \n",
       "43795  0.395659  0.000000      0.0  \n",
       "43796  0.405588  0.000000      0.0  \n",
       "43797  0.413996  0.000000      0.0  \n",
       "43798  0.420866  0.000000      0.0  \n",
       "43799  0.426216  0.000000      0.0  \n",
       "\n",
       "[43799 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()\n",
    "reframed.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 8) 8760 (8760,)\n",
      "(8760, 1, 8) (8760,) (35039, 1, 8) (35039,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 1, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14889336, 0.36764708, 0.24590163, 0.5272732 , 0.6666667 ,\n",
       "       0.00381099, 0.        , 0.        , 0.15995975, 0.4264706 ,\n",
       "       0.22950819, 0.545454  , 0.6666667 , 0.00533197, 0.        ,\n",
       "       0.        , 0.18209255, 0.48529413, 0.22950819, 0.5636368 ,\n",
       "       0.6666667 , 0.00839101, 0.03703704, 0.        , 0.13883299,\n",
       "       0.48529413, 0.22950819, 0.5636368 , 0.6666667 , 0.00991199,\n",
       "       0.07407407, 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12977867, 0.35294122, 0.24590163, 0.5272732 , 0.6666667 ,\n",
       "        0.00229001, 0.        , 0.        ],\n",
       "       [0.14889336, 0.36764708, 0.24590163, 0.5272732 , 0.6666667 ,\n",
       "        0.00381099, 0.        , 0.        ],\n",
       "       [0.15995975, 0.4264706 , 0.22950819, 0.545454  , 0.6666667 ,\n",
       "        0.00533197, 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0,:,]\n",
    "#train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18209255"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8760 samples, validate on 35037 samples\n",
      "Epoch 1/50\n",
      "8760/8760 - 7s - loss: 0.0420 - val_loss: 0.0625\n",
      "Epoch 2/50\n",
      "8760/8760 - 4s - loss: 0.0249 - val_loss: 0.0376\n",
      "Epoch 3/50\n",
      "8760/8760 - 4s - loss: 0.0212 - val_loss: 0.0264\n",
      "Epoch 4/50\n",
      "8760/8760 - 4s - loss: 0.0213 - val_loss: 0.0232\n",
      "Epoch 5/50\n",
      "8760/8760 - 4s - loss: 0.0205 - val_loss: 0.0209\n",
      "Epoch 6/50\n",
      "8760/8760 - 4s - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "8760/8760 - 4s - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 8/50\n",
      "8760/8760 - 4s - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 9/50\n",
      "8760/8760 - 4s - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 10/50\n",
      "8760/8760 - 4s - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 11/50\n",
      "8760/8760 - 4s - loss: 0.0183 - val_loss: 0.0175\n",
      "Epoch 12/50\n",
      "8760/8760 - 4s - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 13/50\n",
      "8760/8760 - 4s - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 14/50\n",
      "8760/8760 - 4s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 15/50\n",
      "8760/8760 - 4s - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 16/50\n",
      "8760/8760 - 4s - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 17/50\n",
      "8760/8760 - 4s - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 18/50\n",
      "8760/8760 - 4s - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 19/50\n",
      "8760/8760 - 4s - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 20/50\n",
      "8760/8760 - 4s - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 21/50\n",
      "8760/8760 - 4s - loss: 0.0151 - val_loss: 0.0171\n",
      "Epoch 22/50\n",
      "8760/8760 - 4s - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 23/50\n",
      "8760/8760 - 4s - loss: 0.0147 - val_loss: 0.0169\n",
      "Epoch 24/50\n",
      "8760/8760 - 4s - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 25/50\n",
      "8760/8760 - 4s - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 26/50\n",
      "8760/8760 - 4s - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 27/50\n",
      "8760/8760 - 4s - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 28/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 29/50\n",
      "8760/8760 - 5s - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 31/50\n",
      "8760/8760 - 4s - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 32/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 33/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 35/50\n",
      "8760/8760 - 4s - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "8760/8760 - 4s - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 37/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 39/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 42/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 43/50\n",
      "8760/8760 - 4s - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 44/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 45/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 46/50\n",
      "8760/8760 - 4s - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 47/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 48/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 49/50\n",
      "8760/8760 - 4s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 50/50\n",
      "8760/8760 - 4s - loss: 0.0143 - val_loss: 0.0141\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.581\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
