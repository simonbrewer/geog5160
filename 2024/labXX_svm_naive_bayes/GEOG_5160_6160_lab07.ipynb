{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOG 5160 6160 Lab 07\n",
    "\n",
    "## Data processing\n",
    "\n",
    "Let's start by by importing the modules we'll need for the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "## Set random seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will start by loading and cleaning the dataset for us. There are several steps we need to take here:\n",
    "\n",
    "- Remove observations with missing values\n",
    "- Create variables containing the average number of bedrooms and rooms per district\n",
    "- Create a Boolean (0/1) variable indicating whether a district is high value or not. We'll define this as being when the median house value for that district is over $250K\n",
    "\n",
    "Now load the data and use the `describe()` method to remind us of the available variables/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 10)\n"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"../datafiles/housing.csv\")\n",
    "print(housing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use the `dropna()` method to remove missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20433, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = housing.dropna()\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the features with the average number of rooms and bedroom ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['avg_rooms'] = housing.total_rooms / housing.households\n",
    "housing['bedroom_ratio'] = housing.total_bedrooms / housing.total_rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create two categorical features for use in the model, both binary. For the first of these, we'll convert the `ocean_proximity` feature into a binary value. This requires a few steps: first we convert this to two groups by with a conditional statement (INLAND vs all other locations); then we convert this to a categorical Series and extract the numerical codes (0/1) using `.cat.codes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_cats = housing.ocean_proximity != \"INLAND\" ## Conditional to make two groups inland vs all others\n",
    "ocean_cats = ocean_cats.astype('category') ## Convert to categorical\n",
    "ocean_cats = ocean_cats.cat.codes ## Extract the code numerical labels (0/1)\n",
    "housing['ocean_new'] = ocean_cats ## Replace original ocean_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the `median_house_value` to a binary outcome of low vs. high house values. We'll initially do this as labels (`low`, `high`). To do this we use Pandas `cut()` function. For $k$ groups, this requires a vector of cuts of length $k+1$, and optionally a vector of labels for the new groups of length $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 2.5e5, np.inf]\n",
    "labels = ['low', 'high']\n",
    "housing['mhv_new'] = pd.cut(housing.median_house_value, bins, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>avg_rooms</th>\n",
       "      <th>bedroom_ratio</th>\n",
       "      <th>ocean_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.570689</td>\n",
       "      <td>35.633221</td>\n",
       "      <td>28.633094</td>\n",
       "      <td>2636.504233</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1424.946949</td>\n",
       "      <td>499.433465</td>\n",
       "      <td>3.871162</td>\n",
       "      <td>206864.413155</td>\n",
       "      <td>5.431344</td>\n",
       "      <td>0.213039</td>\n",
       "      <td>0.682083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003578</td>\n",
       "      <td>2.136348</td>\n",
       "      <td>12.591805</td>\n",
       "      <td>2185.269567</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1133.208490</td>\n",
       "      <td>382.299226</td>\n",
       "      <td>1.899291</td>\n",
       "      <td>115435.667099</td>\n",
       "      <td>2.482946</td>\n",
       "      <td>0.057983</td>\n",
       "      <td>0.465678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563700</td>\n",
       "      <td>119500.000000</td>\n",
       "      <td>4.441441</td>\n",
       "      <td>0.175427</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.536500</td>\n",
       "      <td>179700.000000</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.203162</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3143.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>4.744000</td>\n",
       "      <td>264700.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>0.239821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20433.000000  20433.000000        20433.000000  20433.000000   \n",
       "mean    -119.570689     35.633221           28.633094   2636.504233   \n",
       "std        2.003578      2.136348           12.591805   2185.269567   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1450.000000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.720000           37.000000   3143.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20433.000000  20433.000000   20433.000000   \n",
       "mean       537.870553   1424.946949    499.433465       3.871162   \n",
       "std        421.385070   1133.208490    382.299226       1.899291   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563700   \n",
       "50%        435.000000   1166.000000    409.000000       3.536500   \n",
       "75%        647.000000   1722.000000    604.000000       4.744000   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value     avg_rooms  bedroom_ratio     ocean_new  \n",
       "count        20433.000000  20433.000000   20433.000000  20433.000000  \n",
       "mean        206864.413155      5.431344       0.213039      0.682083  \n",
       "std         115435.667099      2.482946       0.057983      0.465678  \n",
       "min          14999.000000      0.846154       0.100000      0.000000  \n",
       "25%         119500.000000      4.441441       0.175427      0.000000  \n",
       "50%         179700.000000      5.230769       0.203162      1.000000  \n",
       "75%         264700.000000      6.052381       0.239821      1.000000  \n",
       "max         500001.000000    141.909091       1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>avg_rooms</th>\n",
       "      <th>bedroom_ratio</th>\n",
       "      <th>ocean_new</th>\n",
       "      <th>mhv_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.155797</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>0.129516</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>0.184458</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>0.172096</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \\\n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY   \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY   \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY   \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY   \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY   \n",
       "\n",
       "   avg_rooms  bedroom_ratio  ocean_new mhv_new  \n",
       "0   6.984127       0.146591          1    high  \n",
       "1   6.238137       0.155797          1    high  \n",
       "2   8.288136       0.129516          1    high  \n",
       "3   5.817352       0.184458          1    high  \n",
       "4   6.281853       0.172096          1    high  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a quick barplot to show the distribution of our house value categories. This suggests that the data are unbalanced, with more observations in the low than in the high category. We'll want to account for this when designing resampling strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='mhv_new', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"mhv_new\", data=housing, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data for scikit-learn\n",
    "\n",
    "Let's make new DataFrames: one with a subset of variables or features for building our initial model (`X`), and one with the outcome or labels (`y`). We're going to center the continuous variables, so we have to a little more work here than previously. There are a couple of ways to do this, and we'll go through both of them here. \n",
    "\n",
    "In the first method:\n",
    "\n",
    "- We first extract the subset of variables in to a new DataFrame `X`. \n",
    "- Then we take advantage of Pandas `mean()` method to subtract the columns means from each column and create a new DataFrame (`X_scaled`) \n",
    "- As this also removes the mean from the binary variable representing proximity to ocean (`ocean_new`), we replace it with the original value from the `housing` DataFrame. \n",
    "\n",
    "If we now look at the summary of the data, you should see that the mean of all numeric variables is 0 (or close to it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rooms</th>\n",
       "      <th>bedroom_ratio</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>median_income</th>\n",
       "      <th>population</th>\n",
       "      <th>ocean_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.043300e+04</td>\n",
       "      <td>2.043300e+04</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>2.043300e+04</td>\n",
       "      <td>2.043300e+04</td>\n",
       "      <td>20433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.669165e-17</td>\n",
       "      <td>1.390971e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.008995e-16</td>\n",
       "      <td>-9.685609e-14</td>\n",
       "      <td>0.682083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.482946e+00</td>\n",
       "      <td>5.798267e-02</td>\n",
       "      <td>12.591805</td>\n",
       "      <td>1.899291e+00</td>\n",
       "      <td>1.133208e+03</td>\n",
       "      <td>0.465678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.585190e+00</td>\n",
       "      <td>-1.130388e-01</td>\n",
       "      <td>-27.633094</td>\n",
       "      <td>-3.371262e+00</td>\n",
       "      <td>-1.421947e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.899025e-01</td>\n",
       "      <td>-3.761145e-02</td>\n",
       "      <td>-10.633094</td>\n",
       "      <td>-1.307462e+00</td>\n",
       "      <td>-6.379469e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.005747e-01</td>\n",
       "      <td>-9.876396e-03</td>\n",
       "      <td>0.366906</td>\n",
       "      <td>-3.346616e-01</td>\n",
       "      <td>-2.589469e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.210370e-01</td>\n",
       "      <td>2.678186e-02</td>\n",
       "      <td>8.366906</td>\n",
       "      <td>8.728384e-01</td>\n",
       "      <td>2.970531e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.364777e+02</td>\n",
       "      <td>7.869612e-01</td>\n",
       "      <td>23.366906</td>\n",
       "      <td>1.112894e+01</td>\n",
       "      <td>3.425705e+04</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_rooms  bedroom_ratio  housing_median_age  median_income  \\\n",
       "count  2.043300e+04   2.043300e+04        20433.000000   2.043300e+04   \n",
       "mean  -1.669165e-17   1.390971e-17            0.000000   6.008995e-16   \n",
       "std    2.482946e+00   5.798267e-02           12.591805   1.899291e+00   \n",
       "min   -4.585190e+00  -1.130388e-01          -27.633094  -3.371262e+00   \n",
       "25%   -9.899025e-01  -3.761145e-02          -10.633094  -1.307462e+00   \n",
       "50%   -2.005747e-01  -9.876396e-03            0.366906  -3.346616e-01   \n",
       "75%    6.210370e-01   2.678186e-02            8.366906   8.728384e-01   \n",
       "max    1.364777e+02   7.869612e-01           23.366906   1.112894e+01   \n",
       "\n",
       "         population     ocean_new  \n",
       "count  2.043300e+04  20433.000000  \n",
       "mean  -9.685609e-14      0.682083  \n",
       "std    1.133208e+03      0.465678  \n",
       "min   -1.421947e+03      0.000000  \n",
       "25%   -6.379469e+02      0.000000  \n",
       "50%   -2.589469e+02      1.000000  \n",
       "75%    2.970531e+02      1.000000  \n",
       "max    3.425705e+04      1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing[['avg_rooms', 'bedroom_ratio', 'housing_median_age', 'median_income', \n",
    "             'population', 'ocean_new']]\n",
    "X_scaled = X - X.mean()\n",
    "X_scaled.ocean_new = housing.ocean_new\n",
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second way to do this transformation is by using scikit-learn's preprocessing toolkit (called, not surprisingly, `preprocessing`).  \n",
    "\n",
    "- Import the `StandarScaler` function from `preprocessing\n",
    "- Create an array of column names\n",
    "- Use this to create a subset of the original features from `housing` into a new matrix `X`\n",
    "- Create an object `scaler` using `StandardScaler()`. This is an object that holds information about the type of transformation we want to do. By default, this method will standardized numeric variables by first subtracting the mean, then dividing by the standard deviation. The argument `with_std=False` stops this second step. \n",
    "- Once this is set up, we use the `fit()` method to apply this to `X`. As this requires a NumPy array, rather than a Pandas DataFrame, we apply it to the `values()` of `X`\n",
    "- We then back convert this to a Pandas DataFrame (and use the `col_names` array to set the column names)\n",
    "- Finally we add the `ocean_new` column to our new scaled DataFrame. To allow us to copy the values directly over from one DataFrame to another, we first have to make sure the indices align. The easiest way to do this is to simply copy the `housing` index to the `X_scaled` index \n",
    "\n",
    "This is obviously more work than the first way, but it allows a much wider range of data transformations, and we'll illustrate that later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "col_names = ['avg_rooms', 'bedroom_ratio', 'housing_median_age', 'median_income', \n",
    "             'population', 'ocean_new']\n",
    "X = housing[col_names]\n",
    "scaler = StandardScaler(with_std=False).fit(X.values)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X.values), columns = col_names)\n",
    "X_scaled.index = housing.index\n",
    "X_scaled['ocean_new'] = housing.ocean_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create our array of labels (the `mhv_new` variable created earlier). For some ML methods, we can use the text labels, but other methods require this to be a binary (0/1) vector, so we'll create one of those where low value = 0 and high value = 1. \n",
    "\n",
    "We could re-use the code we used earlier to create the `ocean_new` variable, but instead, we're going to use a Pandas function: `get_dummies()`, which provides a little more control over how this binary encoding is set up. If we run this, and look at the output, you'll see that it has create two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       low  high\n",
      "0        0     1\n",
      "1        0     1\n",
      "2        0     1\n",
      "3        0     1\n",
      "4        0     1\n",
      "...    ...   ...\n",
      "20635    1     0\n",
      "20636    1     0\n",
      "20637    1     0\n",
      "20638    1     0\n",
      "20639    1     0\n",
      "\n",
      "[20433 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mhv_dummies = pd.get_dummies(housing.mhv_new)\n",
    "print(mhv_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first encodes for the low values (i.e. 1 = low) and the second encodes for high values (i.e. 1 = high). As we want to model the probability of a district being high value, we can then create our `y` series using the second column. If we were interested in the probability of a district being low value, we could use the first of these two columns as our label.\n",
    "\n",
    "This form of encoding is called 'one-hot' encoding and several uses in machine learning, especially with text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "20635    0\n",
      "20636    0\n",
      "20637    0\n",
      "20638    0\n",
      "20639    0\n",
      "Name: high, Length: 20433, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "y = mhv_dummies.high\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/test split\n",
    "\n",
    "We'll set up a couple of different strategies for testing our models. First, a holdout method with 80% of the data in the training set (this will be used for initial tests). As we noted previously that the data are unbalanced with more 'low' value districts than 'high' value ones, we use the argument `stratify` to do, well, stratified sampling. This will force the training and testing datasets to have the same proportion of low and high value districts as in the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n",
    "                                                    train_size = 0.8,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a 5-fold cross-validation strategy (this will be used to get the final estimate of model skill). Unlike the previous lab, we use the stratified version of $K$-fold cross-validation to keep the proportions of low/high value districts consistent across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# define model evaluation method\n",
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've set up our training and testing sets, we can build the model. The function for logistic regression is part of the linear model methods in scikit-learn, so import this, and create a new logistic regression object. This uses an optimization routine to find the best estimate of the coefficients, and works best for small datasets. As the default setting will not converge for our dataset, we increase the maximum number of iterations for the optimizer (you could alternatively try different optimizers or transformations of the data). \n",
    "\n",
    "The `LogisticRegression` function uses L2 (ridge) regularization by default. For this exercise, we are just going to run non-regularized regression, we set the penalty term to `none`. To see the effect of regularization, set this to `l1` or `l2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "log_reg = linear_model.LogisticRegression(max_iter=200, penalty='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the training data to fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, penalty='none')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can look at the coefficients from this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Coefficients\n",
      "avg_rooms               0.044084\n",
      "bedroom_ratio          10.431983\n",
      "housing_median_age      0.039457\n",
      "median_income           1.285489\n",
      "population              0.000013\n",
      "ocean_new               1.844405\n"
     ]
    }
   ],
   "source": [
    "cdf = pd.DataFrame(log_reg.coef_.transpose(), X_train.columns, columns=['Coefficients'])\n",
    "print(cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.82137429]\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with the test set\n",
    "\n",
    "Next step is to predict the the value of `mhv_new` for for the testing set. If we use the `predict` method, then the values are 0's or 1's. Although the model predicts a probability of a district being high value, this uses a probability threshold of 0.5 probability to distinguish between low and high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = log_reg.predict(X_test)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these predictions to estimate the model performance, and there are several measures that can be easily calculated from scikit-learn's metrics packages. The `classification_report` function calculates the specificity (precision), sensitivity (recall), $f1$-score and accuracy (the proportion of correctly predcited outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      2943\n",
      "           1       0.77      0.61      0.68      1144\n",
      "\n",
      "    accuracy                           0.84      4087\n",
      "   macro avg       0.81      0.77      0.79      4087\n",
      "weighted avg       0.83      0.84      0.83      4087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see the confusion matrix showing the number of correct/incorrect predictions (the diagonal elements are the correct predictions for 0's and 1's in the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2736  207]\n",
      " [ 451  693]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this gives us a good overview of the model performance, the threshold of 0.5 might not be the best way to differentiate between 0's and 1's. To avoid this, we can use the AUC of the receiver operating charactistic (ROC) curve, which is not based on a single threshold. To calculate this, we need the actual predicted probabilities of a district being high value. To get these, we use a different method: `predict_probab`. This returns a two column array where the first column is the probability of a '0' or a low value district, second column is probability of a '1' or high value district. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67106201 0.32893799]\n",
      " [0.99172499 0.00827501]\n",
      " [0.96075451 0.03924549]\n",
      " ...\n",
      " [0.60112198 0.39887802]\n",
      " [0.87768516 0.12231484]\n",
      " [0.8504935  0.1495065 ]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = log_reg.predict_proba(X_test)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are modeling high value districts, we can now calculate the AUC using the second column of this array. The resulting value is quite high, suggesting we have a good model even with this simple algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951776646730775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_test_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the ROC curve that this value is derived from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x15f9ee4c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(log_reg, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC analysis can also be used to find the optimal threshold. There are a couple of ways to find this, but good optimal cut off point would be where true positive rate is high and the false positive rate is low. To find this, we calculate (not just plot) the ROC curve. This gives the false positive rate (`fpr`, the x-axis), the true positive rate (`tpr`, the y-axis) and the set of tested thresholds. We can use this to find the biggest difference between `tpr` and `fpr` and the associated threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24112635840130242"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred[:,1])\n",
    "thresholds[np.argmax(tpr - fpr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run a 5-fold cross-validation to check the stability of the AUC score we got above, using our previously defined cross-validation strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.894 0.83  0.848 0.898 0.901]\n",
      "0.874\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(scores)\n",
    "print(\"%.3f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that our previous AUC score was a little overestimated, and there is some variability across our subsets of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "The Naive Bayes approach tries to establish the conditional probability of any class given the values of the input features. Whichever class has the highest overall probability will be used as a prediction for a new case. These conditional probabilities are built either:\n",
    "\n",
    "- Categorical features: Looking for the relative number of times an output class co-occurs with a feature class \n",
    "- Continuous features: Building a probability function to relate values of the feature to the likelihood of a class (usually based on the mean and s.d. values of the feature for that class)\n",
    "\n",
    "scikit-learn has a couple of different function for Naive Bayes models, which mainly differ in some assumptions about the probabilities. We'll use `GaussianNB` to fit a model, which assumes (surprisingly) a Gaussian distribution.\n",
    "\n",
    "As we have already set up our data and cross-validation strategy, we simply need to load the new method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.867 0.735 0.836 0.872 0.899]\n",
      "0.842\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gnb, X_scaled, y, cv=cv, scoring = 'roc_auc')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(scores)\n",
    "print(\"%.3f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are worse than the logistic regression. This is not too surprising; while the Naive Bayes is a very efficient classifier it is known to be relatively poor in making predictions. It's main use is in classifying large text documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last algorithm we will look at today is a support vector machine (SVM). For classification, these work by projecting the dataset in a parameter space defined by the features, then finding a plane or hyperplane that best discriminates between the classes. \n",
    "\n",
    "This algorithm is sensitive to the values of the features that are used. Any feature with large magnitudes (e.g. income) will have disproportionate effect on the fitted model. In order to avoid this, we are going to scale are features to $z$-scores. To do this, we need subtract the mean, and divide by the standard deviation. Rather than doing this by hand, we'll use the `StandardScaler` function introduced above and set the argument `with_std` to `True`. As before, this will also scale the binary variable `ocean_new` so we replace this with the original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_std=True).fit(X.values)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X.values), columns = col_names)\n",
    "X_scaled.index = housing.index\n",
    "X_scaled['ocean_new'] = housing.ocean_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've rescaled the data, we'll need to remake the training/test split. We could skip this step and go straight to the cross-validation, but this allows us to see some of the results of the SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n",
    "                                                    train_size = 0.8,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up a support vector machine with a linear kernel and fit it to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at some of the output. To see the number of support vectors for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3185 3185]\n"
     ]
    }
   ],
   "source": [
    "support_vectors_per_class = linear_svc.n_support_\n",
    "print(support_vectors_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a few thousand support vectors, suggesting that the dividing hyperplane is quite complex. You can also access the row numbers of each support vector with `support_` and the support vectors themselves with `support_vectors_`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     9    11 ... 16334 16337 16338]\n"
     ]
    }
   ],
   "source": [
    "# Get support vector indices\n",
    "support_vector_indices = linear_svc.support_\n",
    "print(support_vector_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and run the $k$-fold cross-validation for this model (which gives a marginal improvement over the logistic model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.911 0.843 0.861 0.905 0.898]\n",
      "0.884\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(linear_svc, X_scaled, y, cv=cv, scoring = 'roc_auc')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(scores)\n",
    "print(\"%.3f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare this to a SVM built with a radial basis kernel. As before, we set up the SVM (just with a different kernel definition), and run the cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.895 0.821 0.856 0.879 0.874]\n",
      "0.865\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "scores = cross_val_score(rbf_svc, X_scaled, y, cv=cv, scoring = 'roc_auc')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(scores)\n",
    "print(\"%.3f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is surprisingly worse than the linear kernel. This may simply suggest that the dataset is not complex enough to need the different kernel, and the linear methods are sufficient. The SVM algorithm has a couple of key hyperparameters, including $\\gamma$ which modifies the RBF kernel). We'll try re-running the algorithm with $\\gamma = 0.01$. The default is $1/p$ where $p$ is the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.912 0.836 0.863 0.901 0.898]\n",
      "0.882\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.01)\n",
    "scores = cross_val_score(rbf_svc, X_scaled, y, cv=cv, scoring = 'roc_auc')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(scores)\n",
    "print(\"%.3f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping $\\gamma$ from the default value to 0.01 improves the model. In future labs, we'll look at automatically tuning these parameters to optimize your models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The file *Sonar.csv* contains values of 208 sonar signals. The data have 60 features, each representing \"the energy within a particular frequency band, integrated over a certain period of time\", and an outcome variable `Class`, which is coded `M` or `R`. The goal of the experiment is to discriminate between the sonar signals bounced of a rock `R` or a metal object (a mine `M`). \n",
    "\n",
    "For the exercise, you need to carry out a comparison of the three methods presented in today's lab with this new dataset. You should use the **scikit-learn** framework to set up and test your models, and report the cross-validated AUC score for each one. At the end of this exercise, you should make a recommendation as to which method you think is best for this task. \n",
    "\n",
    "Your answer should include\n",
    "\n",
    "- Your jupyter notebook (or word document with your code) [2]\n",
    "- A list of aggregate AUC scores, one per method [1]\n",
    "- A note of any parameter settings you used (e.g. for the SVM method) [1]\n",
    "- The recommendation [1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
