---
title: "GEOG 5160/6160 Lab 09 Neural networks"
author: | 
  | Simon Brewer
  | Geography Department
  | University of Utah
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(png)
library(grid)
```

```{r echo=FALSE}
set.seed(1234)
```

## Introduction

In this lab, we'll go over two neural network examples. These are simple one or two hidden layer networks, and the main purpose of the exercise is to demonstrate how to build the networks and what options are available to modify these. We'll also walk through an example of building a pipeline for a machine learning project. 

The two data files you will need are *cereal.csv* and *credit_data.csv*, which should be available from Canvas with this document. Download these to your `datafiles` folder (extract any zip files). Make a new folder for today's class called `lab09`. 


### R users

Start RStudio and set the working directory to this directory (This can be changed by going to the [Session] menu and selecting [Set working directory] -> [Choose directory...], then browsing to the folder). 

You will need the following packages for today's lab, so make sure to install anything that is missing before proceeding.

- **dplyr**
- **neuralnet**
- **NeuralNetTools**
- **mlr3pipelines**
- **mlr3filters**

### Python users

If you are using Python for today's lab, you'll need to download the Jupyter notebook for this lab (*GEOG_5160_6160_lab08.ipynb*). Make a new folder for the lab (`lab08`) and move the notebook to this. Now open a new terminal (in Windows go to the [Start Menu] > [Anaconda (64-bit)] > [Anaconda prompt]). 

You will need to make sure the following packages are installed on your computer (in addition to the packages we have used in previous labs). 

- **xarray**: functions for working with regular arrays (`conda install xarray`)
- **xgboost**: extreme gradient boosting (`conda install py-xgboost`)

Once opened, change directory to the folder you just made, activate your conda environment

```
conda activate geog5160
```

Start the Jupyter Notebook server:

```
jupyter notebook
```

And open the notebook for today's class. 

## Neural network regression

We'll start with an example of using a neural network for a regression task. The data are taken from a Kaggle competition and are based on a set of 77 breakfast cereals. A description of the data is given in the appendix. The last field in the file (`rating`) is the outcome variable that we will build the network for. Start by loading the packages we'll need for today:

```{r message=FALSE}
library(dplyr)
library(neuralnet)
library(NeuralNetTools)
```

Next, read in the file:

```{r}
# Read the Data
data = read.csv("../datafiles/cereals.csv")
head(data)
```

Next, we'll select a subset of the numeric features for modeling, as well as the outcome variable:

```{r}
mydat = data %>% 
  select(rating, calories, protein, fat, sodium, fiber)
```

To get an overview of the data, we can plot the correlation matrix (the pair-wise correlations between variables). This requires the **GGally** add-on package and can be skipped if you do not have this installed:

```{r}
library(GGally)
ggcorr(mydat, 
               label = TRUE, nbreaks = 6,
               palette = "PuOr")
```

Next, we'll create training set and a hold-out test set using 20% of the data.

```{r}
train_set = sample(nrow(mydat), 0.8 * nrow(mydat))
test_set = setdiff(seq_len(nrow(mydat)), train_set)
train = mydat[train_set, ]
test = mydat[test_set, ]
```

### Linear model

We'll start by making a linear model as a baseline for comparisons with the neural network. 

```{r}
cereal.lm <- lm(rating ~ ., train)
summary(cereal.lm)
```

This is a reasonable model with an R$^2$ of about 0.81. Now, we can test it's predictive skill by calculating the root mean squared error (RMSE). We do this by first predicting for the test set, then:

- Calculating the difference between predicted and observed ratings
- Squaring
- Taking the average
- Taking the square root

```{r}
pred.test = predict(cereal.lm, test)
sqrt(mean((pred.test - test$rating)^2))
```

### Neural network

Now we'll turn to making a neural network. Unfortunately, **mlr3** doesn't yet work with regression neural networks, so we'll have to use original R functions to train and test the model

As the network uses weighted sums of the input features, it's important that none of these are on very different scales. The easiest way to avoid this is to scale all variables to approximately the same range. The scaling we use here is a min-max transformation or *normalization* (i.e. each variable is converted to a 0-1 range). This transformation is given by the following equation. 

\[
x_i'=\frac{x_i-min(x)}{max(x)-min(x)}
\]

We do this in three steps: first calculate the maximum then minimum value for each variable using the `apply()` function. Then we use these to scale the data - effectively setting the smallest value of each variable to 0, the highest value to 1. 

```{r}
maxs = apply(mydat, 2, max)
mins = apply(mydat, 2, min)
scaled = as.data.frame(scale(mydat, center = mins, scale = maxs - mins))
```

Now, we use the same indices for the training and test set form before to create a *scaled* training and test set:

```{r}
train_ <- scaled[train_set,]
test_ <- scaled[test_set,]
```

We can now fit the network. A few things to note:

- This function (`neuralnet`) is taken from the package with the same name. It is not the default neural network package in R. 
- It uses regular R model syntax (`y ~ x`)
- The `hidden` argument dictates the number of nodes in the hidden layer
- `linear.output=TRUE` sets the activation function to be linear

```{r}
# fit neural network
cereal.nn = neuralnet(rating ~ calories + protein + fat + sodium + fiber, 
                      data = train_, hidden = 3 , linear.output = TRUE)
```

Running the `summary()` function on the resulting model object shows that there is a large amount of information provided, including the network weights

```{r results='hide'}
summary(cereal.nn)
```

And we can print the final weights as follows. The first three lines show the final error of the loss function, the amount the error changed in the final step (`reached.threshold`) and the number of iterations (`steps`) run. The next lines show the weight for each connection:

```{r}
cereal.nn$result.matrix
```

We can also plot out these weights to show the final network:

```{r}
# plot neural network
plot(cereal.nn)
```

An alternative visualization is provided in the **NeuralNetTools** package, where the width of the lines reflects the weights and the color reflects the sign (black = positive; grey = negative):

```{r}
plotnet(cereal.nn)
```

We can now calculate the RMSE for this model. The `compute()` function makes predictions from a neural network, and we use it here with the *scaled* test set. Note that we specify that we want to use the function from the **neuralnet** package as there is a conflict with a function in the **dplyr** package:

```{r}
pred.test = neuralnet::compute(cereal.nn, test_)
pred.test = (pred.test$net.result * (maxs[1] - mins[1]) + mins[1])
sqrt(mean((pred.test - test$rating)^2))
```

And we can see that the RMSE has dropped by about 20%. As with the random forest we looked at previously, we can make variable importance plots to show which variables the network is most reliant on. A very good visualization can be made using a function downloaded from a Github page. [This section can be skipped.]

```{r warning=FALSE, results='hide', message=FALSE, eval=FALSE}
#import 'gar.fun' from beckmw's Github - this is Garson's algorithm
devtools::source_gist('6206737')
#use the function on the model created above
gar.fun('rating',cereal.nn)
```

With a small dataset, the RMSE is very dependent on the way the data is split into a training and test set. We can get a better idea of the predictive skill by running a $k$-fold cross-validation (CV). 

The following code will run a 5-fold CV using the one layer neural network. It's a fairly long piece of code, so I strongly suggest copying it or typing it into an R script and running it from there. This script does the following:

- Set the number of folds (`k`)
- Define a NULL object to hold the test results
- Create a vector of indices (1-5) defining which fold each observation belongs to
- Next, run a loop with one iteration per fold. In this loop we:
    - Create a training and test set with the original and  scaled data. This uses the fold index, so for example, we select all rows with fold equal to 1 for the first test set
    - Build a neural network
    - Estimate and store the RMSE
- Finally we calculate and print the average RMSE

```{r}
k = 5
outs <- NULL

foldID = sample(seq(1,k), nrow(mydat), replace = TRUE)
for(i in 1:k)
{
  
  traincv <- mydat[(foldID != i), ]
  testcv <- mydat[(foldID == i), ]
  train_cv <- scaled[(foldID != i), ]
  test_cv <- scaled[(foldID == i), ]
  
  cereal.nn.cv = neuralnet(rating ~ calories + protein + fat + sodium + fiber,
                           data = train_cv, hidden = 3,
                           linear.output = TRUE)
  
  pred.test = neuralnet::compute(cereal.nn, test_cv)
  pred.test = (pred.test$net.result * (maxs[1] - mins[1]) + mins[1])
  
  outs[i] = sqrt(mean((pred.test - testcv$rating)^2))
}

print(mean(outs))
```

And the results show us that the overall network represents a substantial improvement over the linear model. Note that your value will be different due to the random set up of the folds in the cross-validation exercise. 

### Network with more hidden layers

The key parameter in a multi-layer neural network is the definition of the hidden layers, which include

- the number of layers
- the number of nodes in each layer

A good rule of thumb for the number of nodes is that this should be somewhere between the number of input and number of output nodes. However, picking this number is not straightforward. Another good suggestion is that you should generally prefer a smaller number of nodes, but a larger number of layers. 

We'll now see if adding a second hidden layer will improve the model. To do this, we use a vector as the argument in the `neuralnet()` function. Each value in this vector defines how many nodes to include in that layer. Here, we use two hidden layers, with 6 and 3 nodes respectively:

```{r eval=TRUE}
# fit neural network
cereal.nn = neuralnet(rating ~ calories + protein + fat + sodium + fiber, 
                      data = train_, hidden = c(6, 3), 
                      linear.output = TRUE)
plotnet(cereal.nn)
```

```{r echo=FALSE, results='hide'}
k = 5
outs <- NULL

foldID = sample(seq(1,k), nrow(mydat), replace = TRUE)
for(i in 1:k)
{
  
  traincv <- mydat[(foldID != i), ]
  testcv <- mydat[(foldID == i), ]
  train_cv <- scaled[(foldID != i), ]
  test_cv <- scaled[(foldID == i), ]
  
  cereal.nn.cv = neuralnet(rating ~ calories + protein + fat + sodium + fiber,
                           data = train_cv, hidden = 3,
                           linear.output = TRUE)
  
  pred.test = neuralnet::compute(cereal.nn, test_cv)
  pred.test = (pred.test$net.result * (maxs[1] - mins[1]) + mins[1])
  
  outs[i] = sqrt(mean((pred.test - testcv$rating)^2))
}

print(mean(outs))
```

But is this a better model? To find out, we can re-run the 5-fold cross validation shown above. I've not shown the code here, but you simply need to change the `hidden` argument in the cross validation loop. Running this gave me a cross-validated RMSE of `r round(mean(outs),4)` suggesting this more complex model does a better job. 

## Neural network classification

Next, we'll build a neural network for a classification task. We'll use a new dataset, containing credit rankings for over 4000 people (see appendix for a description of the fields). The goal will be to predict `Status`, a binary outcome with two levels: `good` and `bad`. We'll start again by reading the data:

```{r}
credit_data <- read.csv("../datafiles/credit_data.csv")
str(credit_data)
```

As we have several categorical variables, we need to make sure that R recognizes these as factors. The following line of code checks each column in the `credit_data` data frame, and if it contains character data, it then converts it to a factor. Note this is similar to the approach in the previous lab, where we convert individual variables to factors:

```{r}
credit_data <- credit_data %>% mutate_if(is.character,as.factor)
```

If you run the `summary()` function, you should see that there are several missing values:

```{r}
summary(credit_data)
```

As machine learning algorithms can't use missing data to train, we need to decide what to do with these. Fortunately, **mlr3** does have functions for training classification neural networks, so we can take advantage of some of the pre-processing tools in the **mlr3pipelines** library to help with these missing values. Let's first set up a classification task with the credit dataset:

```{r}
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
credit_task <- TaskClassif$new("credit", backend = credit_data,
                               target = "Status")
```

There are several steps that we might want to do to process these data:

- Impute any missing values
- Convert categorical/factor variables to numeric by one-hot encoding
- Scale the numerical variables to prevent biases while training our neural networks

While it is possible to do this in an ad-hoc way (as we did in the previous example), we will set up a processing *pipeline* that contains all of these steps. This takes more time to set up, but has a number of advantages: we can use the pipeline directly in cross-validation or tuning, and we can use it to process any new data that we might to make predictions for, without having to remember the individual steps. The main function is `PipeOps` or `po()` which creates a pipeline operator that will carry our a single data processing step. To see the set of options, simply type:

```{r results='hide'}
library(mlr3pipelines)
mlr_pipeops
```

More information on the individual operations (and some examples) can be found [here][poID]. 

It is possible to set up the full pipeline in one step, but we'll work through this gradually so you can get a sense of what each operator is doing. First, we'll design two operators to process the categorical data. The first (`impute_cat`) will carry out a mode-based imputation of any missing values (i.e. fill in with the most common value). Note that we include an argument `affect_columns` to define which features should be processed (this will ignore any numerical features). The second operator will one-hot encode the same set of features. The argument `method = "treatment"` will drop the first encode column to prevent redundancy and multicollinearity. 

```{r}
impute_cat <- po("imputemode",
             affect_columns = selector_type("factor"))
encode <- po("encode", method = "treatment",
             affect_columns = selector_type("factor"))
```

With these set up, we can now use a pipe function (`%>>%`) to combine these into a pipeline for the categorical features:

```{r}
cat <- impute_cat %>>%
  encode 
```

The pipeline we have just created has a `train()` method. This is does not train a model, but will run the set of operators on a task. We can use this to show what the resulting transformation is:

```{r}
cat$train(credit_task)[[1]]$data()
```

You should see here that each of the original factor variables (e.g. `Home`) has been one-hot encoded, and there are now $m-1$ new features, each representing one level in the original factor (e.g. `Home.owner`). Note that this automatically drops the original feature and has not affected the numerical variables. In fact, if you re-run the `summary()` function on this new dataset, you should see that there are still missing variables in the numerical features

```{r eval=FALSE}
summary(cat$train(credit_task)[[1]]$data())
```

Now we'll set operators for the numerical variables: we'll use median imputation (`imputemedian`) for missing values, and we'll use a min-max scaling to a 0-1 range (`scalerange`):

```{r}
impute_num <- po("imputemedian", 
            affect_columns = selector_type("integer"))
scale <- po("scalerange", param_vals = list(lower = 0, upper = 1), 
            affect_columns = selector_type("integer"))
num <- impute_num %>>%
  scale 
```

As before, we can see the resulting transformation (note that this has not affected any of the factor variables):

```{r}
num$train(credit_task)[[1]]$data()
```
We can now combine these two sets of operators into the full pipeline. 

```{r}
graph <- cat %>>%
  num
```

If you now run this on the credit task, the resulting dataset has the full set of encode variables and has now imputed values for anything that was missing. 

```{r}
graph$train(credit_task)[[1]]$data()
summary(graph$train(credit_task)[[1]]$data())
```

So far, we have a pipeline that transforms the dataset into a format ready for modeling. The next step is to link it to a learner, so that we can pass the transformed data directly to it. We'll set up a classification based neural network, with 10 nodes in the hidden layer and a maximum iteration limit of 500:

```{r eval=FALSE}
lrn_nn <- lrn("classif.nnet", size = 10, maxit = 500)
```

```{r echo=FALSE}
lrn_nn <- lrn("classif.nnet", size = 10, maxit = 500, trace = FALSE)
```

And we can just add this to our existing pipeline

```{r}
graph <- cat %>>%
  num %>>%
  lrn_nn
```

**mlr3** uses a graph framework to connect all the pieces of a framework, which means that it can use R-based tools to visualize the pipeline:

```{r}
plot(graph)
```

Now if we call the `train()` method on the credit task, the data gets passed throught the pipeline, transformed, encoded and imputed and then used to train the neural network:

```{r message=FALSE}
graph$train(credit_task)
```

As the pipeline is connected to a learner, we can also use this to cross-validate the model trained on the transformed data. We first convert the pipeline to a `GraphLearner()`. This has the same attributes as a basic `learner` object and will facilitate the cross-validation

```{r}
glrn = GraphLearner$new(graph)
```

Now we can set up a 5-fold cross-validation, and calculate the AUC for our neural network. 
```{r echo=FALSE}
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
```

```{r}
resampling = rsmp("cv", folds = 5)
resampling$instantiate(credit_task)
measure = msr("classif.auc")
rr = resample(credit_task, glrn, resampling, store_models = TRUE)
```

```{r}
rr$score(measure)
rr$aggregate(measure)
```

Alternatively, we can use our combined pipeline and learner to tune hyperparameters of the learner. We'll try tuning the number of nodes in the hidden layer, the `size` argument to between 2 and 20. To see the full set of available hyperparameters, just type `glrn$param_set`.

```{r}
library(paradox)
tune_ps = ParamSet$new(list(
  ParamInt$new("classif.nnet.size", lower = 2, upper = 20)
))
tune_ps
```

If you are wondering where the name of the hyperparameter we are tuning (`classif.nnet.size`) comes from, it's a combination of the learner `classif.nnet` and the parameter in the learner (`size`). To check the names of hyperparameters in *any* learner, just type: `glrn$param_set`.

Now we set up a terminating condition (20 evaluations), and a search strategy (simple random choice):

```{r}
evals = trm("evals", n_evals = 20)
tuner = tnr("random_search")
```

And finally, we build an `AutoTuner` to carry out the tuning using a simple holdout strategy. Note that we can just pass the graph-based learner to this function:

```{r}
at_nn = AutoTuner$new(learner = glrn, 
                      resampling = rsmp("holdout"),
                      measure = measure, 
                      search_space = tune_ps,
                      terminator = evals,
                      tuner = tuner)
```

And with that done, it's time to tune the model (this will take a few seconds):

```{r message=FALSE}
at_nn$train(credit_task)
```

```{r}
at_nn$learner
at_nn$tuning_result
```

The final selected model as a hidden layer size of `r at_nn$tuning_result$classif.nnet.size` and an AUC of `r round(at_nn$tuning_result$classif.auc, 2)`. 

We can use the tuned learner to make predictions for a new data set. As the learner is built on the data transformation pipeline, we do need to carry out any transformations prior to prediction. Instead we can simply pass the new data to the learner, and leave it to do all that for us. We'll create a single example and use the `predict_new()` method to get a prediction of credit risk (feel free to use different values to see the impact here):

```{r}
new_credit <- data.frame(Seniority = 8, 
                         Home = "rent",
                         Time = 36,
                         Age = 26,
                         Marital = "single",
                         Records = "no",
                         Job = "fixed",
                         Expenses = 50,
                         Income = 100,
                         Assets = 0,
                         Debt = 10,
                         Amount = 100,
                         Price = 125)

at_nn$learner$predict_newdata(newdata = new_credit)
```

### Feature selection

When working with datasets with large numbers of features we often want to reduce the number of features used to build the model. We can further modify the pipeline to allow for feature selection using the **mlr3filters** package. The full set of filters can be found on the package [website][filID] or by typing:

```{r}
library(mlr3filters)
mlr_filters
```

We'll use the `mim` filter. For a given classification task this calculates an information based correlation between the outcome and each feature and then selects the subset with the highest values. We'll use this to pick the top 3 features. As we want to use this in the pipeline, we again use the `po()` function to create a new operator. We specify the filter type (`mim`) and the number of features we want to retain:

```{r}
filter_mim <-   po("filter", flt("mim"), filter.nfeat = 3)
```

We then just need to add this to our pipeline

```{r}
graph <- cat %>>%
  num %>>%
  filter_mim 
```

And you can see which features are selected:

```{r}
graph$train(credit_task)[[1]]$data()
```

Note that one impact of running this following the one-hot encoding is that the filter might select the encoding of *individual* levels of the original factor. 

We don't, however, know if 3 is the best subset of variables to include in the model. This is where the link between the pipeline, learner and tuning becomes very useful as we can tune this parameter (`filter.nfeat`) just as we would tune any hyperparameter. To do this, first create a new `GraphLearner` with the combination of data transformations, filter and learner:

```{r}
graph <- cat %>>%
  num %>>%
  filter_mim %>>%
  lrn_nn

glrn = GraphLearner$new(graph)
```

Now set up a new tuning grid that includes both the number of features and the number of nodes in the hidden layer (as a reminder, type `glrn$param_set` to see the parameter names)

```{r}
tune_ps = ParamSet$new(list(
  ParamInt$new("mim.filter.nfeat", lower = 2, upper = 20),
  ParamInt$new("classif.nnet.size", lower = 2, upper = 20)
))
tune_ps
```

Now we set up the tuning strategy (terminator, search):

```{r}
evals = trm("evals", n_evals = 50)
tuner = tnr("random_search")
at_nn = AutoTuner$new(learner = glrn, 
                      resampling = rsmp("holdout"),
                      measure = measure, 
                      search_space = tune_ps,
                      terminator = evals,
                      tuner = tuner)
```

And finally run. This will take a little while as we are building and testing 50 models. Note that this is not a very exhaustive search as we have about 320 (18*18) parameter combinations, and you might want to increase `n_evals` if you have the time.

```{r}
at_nn$train(credit_task)
```

Let's take a look at the output

```{r}
at_nn$learner
at_nn$tuning_result
```

### PCA transformation

For a final example, we'll look at a different feature selection strategy. Rather than selecting out original features, we'll use a PCA transformation to create new features. These are based on the original features, but a) are uncorrelated and b) try to maximize the amount of information contained in each one. 

To do this, we'll recreate our pipeline with a new operator that will carry out the PCA transformation (`pca`). We also add a new filter that selects the set of new features based on how much of the original variation in the dataset that they explain (we'll start by choosing the set that explain >50%).


```{r}
pca <- po("pca")
filter <- po("filter", filter = mlr3filters::flt("variance"), filter.frac = 0.5)
graph <- cat %>>%
  num %>>%
  pca %>>% 
  filter
```
Let's take a look at the transformed data:

```{r}
graph$train(credit_task)[[1]]$data()
```

Which gives us `r ncol(graph$train(credit_task)[[1]]$data()) - 1` new features, called PC1, etc. Now we'll connect this pipeline to our learner:

```{r}
graph <- cat %>>%
  num %>>%
  pca %>>% 
  filter %>>%
  lrn_nn

plot(graph)
```
And create a new GraphLearner

```{r}
glrn = GraphLearner$new(graph)
```

With all this in place, we can now tune our model. We'll again tune the size of the hidden layer, but we'll also use tune the number of new PC features that we use in the model by tuning the `filter.frac` parameter.

- Set up parameter space
```{r}
tune_ps = ParamSet$new(list(
  ParamDbl$new("variance.filter.frac", lower = 0.05, upper = 0.95),
  
  ParamInt$new("classif.nnet.size", lower = 2, upper = 20)
))
tune_ps
```

- Set up terminator and search strategy (these are the same as before):

```{r}
evals = trm("evals", n_evals = 50)
tuner = tnr("random_search")
```

- Set up the `AutoTuner`

```{r}
at_nn = AutoTuner$new(learner = glrn, 
                      resampling = rsmp("holdout"),
                      measure = measure, 
                      search_space = tune_ps,
                      terminator = evals,
                      tuner = tuner)
```

- And tune

```{r}
at_nn$train(credit_task)
```

When this is eventually done, inspect the output to see the final choices for the two hyperparameters, as well as the final AUC:

```{r}
at_nn$learner
at_nn$tuning_result
```


## Exercise

For the exercise we will once again use the data from the *Sonar.csv* file to model types of object (rocks 'R' or mines 'M') using the values of a set of frequency bands. The goal of the exercise is to build the best predictive neural network for predicting these data. As this is a classification task, you can use the **mlr3** framework to setup, train and test your model. You will need to choose a cross-validation strategy and calculate the AUC to assess the model. 

As the data has a large number of features, you should build a pipeline to reduce the number of features using one of the two filter examples (mutual information or PCA) from the lab. Note that there are no categorical features so you can skip those steps. You should then tune both the filter and the size of the hidden layer in the network.

Your answer should consist of the following

- A description of your pipeline (this can include a figure showing the steps)
- The values you obtained for the number of features and the size of the hidden layer through tuning
- The cross-validated AUC

You should also provide your full R code. 

## Appendix

### Cereal data set

From https://www.kaggle.com/crawford/80-cereals

|    | Column name | Feature                | 
|----|-------------|------------------------|
| 1  | `Name`      | Name of cereal          |
| 2  | `mfr`       | Manufacturer of cereal  |
|    |             | A = American Home Food Products |
|    |             | G = General Mills |
|    |             | K = Kelloggs |
|    |             | N = Nabisco |
|    |             | P = Post |
|    |             | Q = Quaker Oats |
|    |             | R = Ralston Purina |
| 3  | `type`      | cold or hot |
| 4  | `calories`  | calories per serving |
| 5  | `protein`   | grams of protein          |
| 6  | `fat`       | grams of fat         |
| 7  | `sodium`    | milligrams of sodium   |
| 8  | `fiber`     | grams of dietary fiber           |
| 9  | `carbo`     | grams of complex carbohydrates   |
| 10 | `sugars`    | grams of sugars       |
| 11 | `potass`    | milligrams of potassium       |
| 12 | `vitamins`  | vitamins and minerals - 0, 25, or 100,          |
|    |             | indicating the typical percentage of FDA recommended         |
| 13 | `shelf`     | display shelf (1, 2, or 3, counting from the floor) |
| 14 | `weight`    | weight in ounces of one serving         |
| 15 | `cups`      | number of cups in one serving          |
| 16 | `rating`    | a rating of the cereals          |

### Credit data set 

From https://github.com/gastonstat/CreditScoring

|    | Column name | Feature                | 
|----|-------------|------------------------|
| 1  | `Status`    | credit status          |
| 2  | `Seniority` | job seniority (years)  |
| 3  | `Home`      | type of home ownership |
| 4  | `Time`      | time of requested loan |
| 5  | `Age`       | client's age           |
| 6  | `Marital`   | marital status         |
| 7  | `Records`   | existence of records   |
| 8  | `Job`       | type of job            |
| 9  | `Expenses`  | amount of expenses     |
| 10 | `Income`    | amount of income       |
| 11 | `Assets`    | amount of assets       |
| 12 | `Debt`      | amount of debt         |
| 13 | `Amount`    | loan amount requested  |
| 14 | `Price`     | price of good          |

[poID]: https://mlr3pipelines.mlr-org.com
[filID]: https://mlr3filters.mlr-org.com/index.html
