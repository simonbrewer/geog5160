---
title: "GEOG 5160 6160 Lab 04"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 S Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(png)
library(grid)
set.seed(42)
```

# Introduction

While machine learning methods have been frequently used with spatial data, there is a growing awareness of how the characteristics of these data may cause some issues. In this lab, we'll look at how more robust methods of evaluating machine learning models with spatial data, and at some approaches that can incorporate location and improve predictions. 

We'll use a couple of datasets to illustrate these methods:

- *lsl.csv*: Location of landslide events in southern Ecuador
- *ta.tif*: A raster file with environmental predictors
- *data_atlantic_1998_2012.csv*: A dataset of cancer rates for counties in Atlantic states
- *COUNTY_ATLANTIC.zip*: a shapefile for the Atlantic States

You will need to make sure the following packages are installed on your computer (in addition to the packages we have used in previous labs).

-   **terra**: working with raster data
-   **sf**: working with spatial data
-   **tmap**: making thematic maps
-   **spatialsample**: spatial sampling
-   **SpatialML**: geographic random forests
-   **FRK**: spatial basis functions

As a reminder, packages can be installed in RStudio by going to the 'Packages' tab and clicking on the \[Install\] button, or from the menu \[Tools\]-\> \[Install packages...\]. You can also install these from the console window by typing

```{r eval=FALSE}
install.packages("terra")
```

## Objectives

-   Understand how to use different cross-validation strategies for spatial data
-   Use a geographic random forest to explore spatial variations in model results
-   Incorporate location in machine learning models

**It is highly recommended to use scripts or Quarto documents to store your R code - this will allow you to easily change and modify it and submit the exercise.**

Next load the libraries you will need for the lab. You should at this stage have most of these already installed. Add anything that is not installed using the `install.packages()` function.

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(sf)
library(terra)
library(tmap)
```

## Data processing

Let's load the landslide data first and take a look at the content:

```{r}
lsl = read.csv("./datafiles/lsl.csv")
head(lsl)
```

The first two columns show the easting and northing. The third indicates whether or not a landslide had occurred at that location (the target) and the remaining columns are features to be used in the model. See the appendix for more detail on these. 

```{r}
lsl <- lsl |>
  mutate(lslpts = as.factor(as.numeric(lslpts)))
```

We can use the `st_as_sf` function from the **sf** package to conver these to a simple features spatial object and plot:

```{r}
lsl_sf <- st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
plot(st_geometry(lsl_sf))
```

And we can use the thematic mapping package to show the distribution of the landslide points:

```{r}
tm_shape(lsl_sf) +
  tm_symbols(col = "lslpts") +
  tm_scale_bar(position = c("left", "top")) +
  tm_compass(position = c("right", "top"))
```

```{r}
lsl = read.csv("./datafiles/lsl.csv")
head(lsl)
```

```{r}
lsl <- lsl |>
  mutate(lslpts = as.factor(as.numeric(lslpts)))
```

```{r}
lsl_sf <- st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
plot(st_geometry(lsl_sf))
```

```{r}
tm_shape(lsl_sf) +
  tm_symbols(col = "lslpts") +
  tm_scale_bar(position = c("left", "top")) +
  tm_compass(position = c("right", "top"))
```

Next let's load some environmental data to make predictions. This is in a multi-layer GeoTIFF file, and we can load it using the `rast` function from **terra**:

```{r}
env <- rast("./datafiles/ta.tif") 

env
```

Each of the individual layers can be accessed using R's list notation, with two brackets. So to map the `log10_carea` values:

```{r}
tm_shape(env[["log10_carea"]]) +
  tm_raster(style = "sd") +
  tm_shape(lsl_sf) +
  tm_dots()
```

# Spatial prediction

First, let's build a simple model using a classic train/test split (80/20) and evaluate it. First create the training/test split. Note that the data is well balanced (equal numbers of 1's and 0's) so we don't need to worry about stratifying the sample:

```{r}
library(tidymodels)
dat_split <- initial_split(lsl, prop = 0.80)

dat_train <- training(dat_split)
dat_test  <- testing(dat_split)
```

Next, we'll build a model. We're going use a random forest without tuning, so we can simply:

- Set up the formula to define the target (`lslpts`) and the features
- Instantiate a random forest object
- Fit the model using the training set

```{r}
lsl_f <- lslpts ~ slope + cplan + cprof + elev + log10_carea

rf <- rand_forest(mode = "classification")

rf_fit <- rf |> 
  fit(lsl_f, dat_train)
```

We'll get a first evaluation here using the AUC:

```{r}
y_test_pred <- predict(rf_fit, dat_test, type = 'prob') |>
  bind_cols(dat_test |> dplyr::select(lslpts))

roc_auc(y_test_pred, lslpts, .pred_1, event_level = 'second')
```

We get an AUC of around 0.88, which indicates a pretty good model. We'll dig into this more below. 

Next, let's predict landslide susceptibility for the study region using the raster images we loaded above. In the previous lab, we did this by extracting all the values to a data frame, and then predicting. An easier way is to use the `predict` function that comes with the **terra** package, which allows direct prediction on raster layers. We'll do this below, but a few things to note:

- We use the `::` notation to force R to use the `predict` function from the **terra** package (there are other packages with the same function name)
- We use the fitted model from the tidymodels object (`rf_fit$fit`)
- We set the `type` to `response` to get predictions on a 0-1 scale
- Last, and possibly most important, the input raster (`env`) must have the same names for the layers as the columns in the data frame used to fit the model

Let's now predict:

```{r}
lsl_pred = terra::predict(env, model = rf_fit$fit, 
                          type = "response", na.rm = TRUE)
```

And plot. Note that this gives two rasters as output: a) the probability of the *absence* of a landslide and b) the probability of *presence*

```{r}
plot(lsl_pred[["X1"]])
```

# Spatial cross-validation

## Non-spatial XV

```{r}
library(tidymodels)

rec <- recipe(lslpts ~ slope + cplan + cprof + elev + log10_carea, lsl)

rf <- rand_forest(mode = "classification")

nfolds = 5

folds <- vfold_cv(lsl, v = nfolds)

workflow <- workflow() |>
  add_recipe(rec) |>
  add_model(rf)

results <- workflow |>
  fit_resamples(resamples = folds, 
                metrics = metric_set(accuracy, roc_auc))

collect_metrics(results)
```

## Spatial XV

```{r}
library(spatialsample)
spfolds <- spatial_clustering_cv(data = lsl_sf, 
                                 v = nfolds)
autoplot(spfolds)
```

```{r}
rec <- recipe(lslpts ~ slope + cplan + cprof + elev + log10_carea, lsl_sf)

rf <- rand_forest(mode = "classification")

workflow <- workflow() |>
  add_recipe(rec) |>
  add_model(rf)

results <- workflow |>
  fit_resamples(resamples = spfolds, 
                metrics = metric_set(accuracy, roc_auc))

collect_metrics(results)
```



# Exercise

For the exercise, you will need to submit two things:

-   A table listing the AUC and accuracy for the three different algorithms (decision trees, random forest and boosted regression). You should give these values based on predictions for the *test* dataset using the final model.
-   A map showing predicted *probability* of Pinus edulis presence under *current* environmental conditions using *either* the decision tree model or the boosted regression

Students enrolled in 6160 should also provide

-   A map showing predicted *probability* of Pinus edulis presence under *future* environmental conditions using the same model as in part 2
-   A map showing the difference between the future and current predicted presence for the same model

Use a Quarto document to record your answers and output. Assignments, to include both the Quarto document and (ideally) the compiled HTML file, should be submitted to Canvas by Feb 12th. Please use the following naming convention: `Lab04_lastname`.

# Appendix 1: Datafiles

## *lsl.csv* 

- `x`: easting (m)
- `y`: northing (m)
- `lslpts`: presence or absence of landslide (`[0,1]`)
- `slope`: slope angle (degrees)
- `cplan`: plan curvature (rad mâˆ’1) expressing the convergence or divergence of a slope and thus water flow
- `cprof`: profile curvature (rad m-1) as a measure of flow acceleration, also known as downslope change in slope angle
- `elev`: elevation (m a.s.l.) as the representation of different altitudinal zones of vegetation and precipitation in the study area
- `log10_carea`: the decadic logarithm of the catchment area (log10 m2) representing the amount of water flowing toward a location

## *ta.tif*

Raster dataset with same predictor variables as *lsl.csv*

## *data_atlantic_1998_2012.csv*


